# 2.2.1 Data Consistency

In [Section 2.1.4](2-01-04-DataSourcesAndFormats.md) we saw how to load data of different types into pandas. In this section we'll look at first steps you can perform to look at the data, understand what it contains, and a few common issues that may come up with data consistency like missing or mis-interpreted values.

## Domain Knowledge

Before jumping into looking at and analysing the data you should check any information you've been given about it, so you know what to expect. In this section we'll be using the Palmer penguins dataset, adapted from the version created by Allison Horst available [here (doi:10.5281/zenodo.3960218)](https://allisonhorst.github.io/palmerpenguins/).

We've made changes to the data to demonstrate the concepts we're teaching, adding missing values and other common data issues. The (cleaner) original file is available [here](https://github.com/allisonhorst/palmerpenguins/blob/master/inst/extdata/penguins.csv).

The dataset was originally collected and made available by [Dr.Â Kristen Gorman](https://www.uaf.edu/cfos/people/faculty/detail/kristen-gorman.php) and the [Palmer Station, Antarctica LTER](https://pal.lternet.edu/), a member of the [Long Term Ecological Research Network](https://lternet.edu/), and published in the [PLOS ONE journal (doi:10.1371/journal.pone.0090081)](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0090081) in 2014 .

It includes measurements of the bill size, flipper length and weight of three different species of penguin (AdÃ©lie, Chinstrap, Gentoo) on three different islands (Biscoe, Dream, Torgersen) in the Palmer Archipelago, Antarctica. The [dataset homepage](https://allisonhorst.github.io/palmerpenguins/) contains more information about the columns and data types we expect. To reiterate, it's always important to check the documentation and associated literature first.

| ![lter_penguins.png](data/lter_penguins.png) | 
|:--:| 
| *Artwork by [@allison_horst](https://twitter.com/allison_horst).* |

## Having a First Look at the Data

The dataset is saved in `data/penguins.csv` and we can load it with [`pd.read_csv`](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html?highlight=read_csv#pandas.read_csv), as seen previously:


```python
import pandas as pd
import numpy
```


```python
df = pd.read_csv("data/penguins.csv")
```

Display the first few ten rows of the data:


```python
df.head(10)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Id</th>
      <th>species</th>
      <th>island</th>
      <th>bill_length_mm</th>
      <th>bill_depth_mm</th>
      <th>flipper_length_mm</th>
      <th>body_mass_g</th>
      <th>sex</th>
      <th>year</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>P-179</td>
      <td>Gentoo</td>
      <td>Biscoe</td>
      <td>47.8</td>
      <td>15.0</td>
      <td>215.0</td>
      <td>5650.0</td>
      <td>male</td>
      <td>2007</td>
    </tr>
    <tr>
      <th>1</th>
      <td>P-306</td>
      <td>Chinstrap</td>
      <td>Dream</td>
      <td>40.9</td>
      <td>16.6</td>
      <td>187.0</td>
      <td>3200.0</td>
      <td>female</td>
      <td>2008</td>
    </tr>
    <tr>
      <th>2</th>
      <td>P-247</td>
      <td>Gentoo</td>
      <td>Biscoe</td>
      <td>50.8</td>
      <td>15.7</td>
      <td>226.0</td>
      <td>5200.0</td>
      <td>male</td>
      <td>2009</td>
    </tr>
    <tr>
      <th>3</th>
      <td>P-120</td>
      <td>Adelie</td>
      <td>Torgersen</td>
      <td>36.2</td>
      <td>17.2</td>
      <td>187.0</td>
      <td>3150.0</td>
      <td>female</td>
      <td>2009</td>
    </tr>
    <tr>
      <th>4</th>
      <td>P-220</td>
      <td>Gentoo</td>
      <td>Biscoe</td>
      <td>43.5</td>
      <td>14.2</td>
      <td>220.0</td>
      <td>4700.0</td>
      <td>female</td>
      <td>2008</td>
    </tr>
    <tr>
      <th>5</th>
      <td>P-150</td>
      <td>Adelie</td>
      <td>Dream</td>
      <td>36.0</td>
      <td>17.1</td>
      <td>187.0</td>
      <td>3700.0</td>
      <td>female</td>
      <td>2009</td>
    </tr>
    <tr>
      <th>6</th>
      <td>P-348</td>
      <td>Adelie</td>
      <td>Biscoe</td>
      <td>36.4</td>
      <td>18.1</td>
      <td>193.0</td>
      <td>285.0</td>
      <td>female</td>
      <td>2007</td>
    </tr>
    <tr>
      <th>7</th>
      <td>P-091</td>
      <td>Adelie</td>
      <td>Dream</td>
      <td>41.1</td>
      <td>18.1</td>
      <td>205.0</td>
      <td>4300.0</td>
      <td>male</td>
      <td>2008</td>
    </tr>
    <tr>
      <th>8</th>
      <td>P-327</td>
      <td>Chinstrap</td>
      <td>Dream</td>
      <td>51.4</td>
      <td>19.0</td>
      <td>201.0</td>
      <td>3950.0</td>
      <td>male</td>
      <td>2009</td>
    </tr>
    <tr>
      <th>9</th>
      <td>P-221</td>
      <td>Gentoo</td>
      <td>Biscoe</td>
      <td>50.7</td>
      <td>15.0</td>
      <td>223.0</td>
      <td>5550.0</td>
      <td>male</td>
      <td>2008</td>
    </tr>
  </tbody>
</table>
</div>



We could also look at the last few rows of the data with `df.tail()`, or a random sample of rows with `df.sample()`.

To check the number of rows and columns we can use:


```python
print(df.shape)
```

    (351, 9)


Our data has 351 rows and 9 columns. It might also be useful to look at the column names (especially for larger datasets with many columns where they may not all be displayed by `df.head()`):


```python
print(df.columns)
```

    Index(['Id', 'species', 'island', 'bill_length_mm', 'bill_depth_mm',
           'flipper_length_mm', 'body_mass_g', 'sex', 'year'],
          dtype='object')


A useful command that summarises much of this information is `df.info()`:


```python
df.info()
```

    <class 'pandas.core.frame.DataFrame'>
    RangeIndex: 351 entries, 0 to 350
    Data columns (total 9 columns):
     #   Column             Non-Null Count  Dtype  
    ---  ------             --------------  -----  
     0   Id                 351 non-null    object 
     1   species            351 non-null    object 
     2   island             351 non-null    object 
     3   bill_length_mm     347 non-null    float64
     4   bill_depth_mm      349 non-null    object 
     5   flipper_length_mm  349 non-null    float64
     6   body_mass_g        349 non-null    float64
     7   sex                340 non-null    object 
     8   year               351 non-null    int64  
    dtypes: float64(3), int64(1), object(5)
    memory usage: 24.8+ KB


This gives us the number of rows (entries) and columns at the top, and then a table with the name, number of non-null values, and data type of each column. Finally, it gives the amount of memory the data frame is using. Pandas can use a lot of memory, which may cause problems when analysing large datasets. The [Scaling to large datasets](https://pandas.pydata.org/pandas-docs/stable/user_guide/scale.html) page in the Pandas documentation gives pointers for what you can try in that case.

## Null Values

The data frame info shows we have 351 "non-null" values in the `Id`, `species`, `island` and `year` columns, but fewer in the other columns.

"Null values" is Pandas' way of describing data that is missing. Under the hood, these are encoded as NumPy's NaN (not a number) constant (see [here](https://numpy.org/doc/stable/reference/constants.html#numpy.nan)), which has type `float64` so numeric columns with NaN values still have a numeric type and can have numeric operations applied to them.

To find missing values in a column we can use the `isnull()` function:



```python
is_missing = df["bill_length_mm"].isnull()
print(is_missing)
```

    0      False
    1      False
    2      False
    3      False
    4      False
           ...  
    346    False
    347    False
    348    False
    349    False
    350    False
    Name: bill_length_mm, Length: 351, dtype: bool


This returns a boolean series which is True if that row's value is NaN, which can then be used to filter the data frame and show only the rows with missing data in the `bill_length_mm` column:


```python
df[is_missing]
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Id</th>
      <th>species</th>
      <th>island</th>
      <th>bill_length_mm</th>
      <th>bill_depth_mm</th>
      <th>flipper_length_mm</th>
      <th>body_mass_g</th>
      <th>sex</th>
      <th>year</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>233</th>
      <td>P-344</td>
      <td>Chinstrap</td>
      <td>Dream</td>
      <td>NaN</td>
      <td>19.2</td>
      <td>197.0</td>
      <td>4000.0</td>
      <td>male</td>
      <td>2008</td>
    </tr>
    <tr>
      <th>286</th>
      <td>P-003</td>
      <td>Adelie</td>
      <td>Torgersen</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>2007</td>
    </tr>
    <tr>
      <th>307</th>
      <td>P-271</td>
      <td>Gentoo</td>
      <td>Biscoe</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>2009</td>
    </tr>
    <tr>
      <th>312</th>
      <td>P-345</td>
      <td>Adelie</td>
      <td>Torgersen</td>
      <td>NaN</td>
      <td>18.0</td>
      <td>193.0</td>
      <td>43400.0</td>
      <td>female</td>
      <td>2009</td>
    </tr>
  </tbody>
</table>
</div>



There are many reasons data could be missing and how you choose to deal with them is an important part of any research project. We'll revisit this later. 

## Unexpected Column Types

Looking at the first few rows of our data (the output of `df.head()` above) it looks like we expect the `bill_length_mm`, `bill_depth_mm`, `flipper_length_mm`, `body_mass_g` and `year` columns to have a numeric type. Comparing with the output of `df.info()` above most of them do, having a `dtype` (data type) of either `int64` or `float64`.

However, the `bill_depth_mm` column has a dtype of `object`, which usually means the column is being treated as strings/text data. This will generally  be because there is at least one row in the column that Pandas was not able to parse as a number. Common reasons this might happen include:
- Data entry errors and typos, for example "23/15" instead of "23.15".
- Encoding of missing values: The `pd.read_csv()` function checks for common string representations of missing values like "NA" or "NULL" and converts these to `numpy.nan` when loading the data. But many different conventions for missing data exist, such as more verbose representations like "UNKNOWN", and Pandas will load these as strings by default. This can be customised with the `na_values` parameter of [`pd.read_csv()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html).
- Additional metadata incorrectly loaded into the data frame, such as CSV files with headers and footers (as seen in the [Data Sources & Formats section](2-01-04-DataSourcesAndFormats) previously).

To see what's wrong with the `bill_depth_mm` column we can try to convert it to a numeric type with the [`pd.to_numeric`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.to_numeric.html) function:



```python
df["bill_depth_mm"] = pd.to_numeric(df["bill_depth_mm"])
```


    ---------------------------------------------------------------------------

    ValueError                                Traceback (most recent call last)

    File ~/Library/Caches/pypoetry/virtualenvs/rds-course-5zqYD5aN-py3.9/lib/python3.9/site-packages/pandas/_libs/lib.pyx:2369, in pandas._libs.lib.maybe_convert_numeric()


    ValueError: Unable to parse string "14,2"

    
    During handling of the above exception, another exception occurred:


    ValueError                                Traceback (most recent call last)

    Cell In[9], line 1
    ----> 1 df["bill_depth_mm"] = pd.to_numeric(df["bill_depth_mm"])


    File ~/Library/Caches/pypoetry/virtualenvs/rds-course-5zqYD5aN-py3.9/lib/python3.9/site-packages/pandas/core/tools/numeric.py:185, in to_numeric(arg, errors, downcast)
        183 coerce_numeric = errors not in ("ignore", "raise")
        184 try:
    --> 185     values, _ = lib.maybe_convert_numeric(
        186         values, set(), coerce_numeric=coerce_numeric
        187     )
        188 except (ValueError, TypeError):
        189     if errors == "raise":


    File ~/Library/Caches/pypoetry/virtualenvs/rds-course-5zqYD5aN-py3.9/lib/python3.9/site-packages/pandas/_libs/lib.pyx:2411, in pandas._libs.lib.maybe_convert_numeric()


    ValueError: Unable to parse string "14,2" at position 142


The error above tells us Pandas has encountered a value "14,2", which it doesn't know how to convert into a number. It also says the problem is at index 142, which we can access ourselves to check the value directly:


```python
df.loc[142, "bill_depth_mm"]
```




    '14,2'



In this case it looks like a typo, the person entering the data probably meant to write `14.2`, but we should check this first. There may be information in the data documentation, or you could ask the data provider.

Let's say we're confident it is a typo. We can fix it ourselves and then convert the column to a numeric type:


```python
# set the incorrectly typed number to its intended value
df.loc[142, "bill_depth_mm"] = 14.2
# convert the column to a numeric type
df["bill_depth_mm"] = pd.to_numeric(df["bill_depth_mm"])

df.info()
```

    <class 'pandas.core.frame.DataFrame'>
    RangeIndex: 351 entries, 0 to 350
    Data columns (total 9 columns):
     #   Column             Non-Null Count  Dtype  
    ---  ------             --------------  -----  
     0   Id                 351 non-null    object 
     1   species            351 non-null    object 
     2   island             351 non-null    object 
     3   bill_length_mm     347 non-null    float64
     4   bill_depth_mm      349 non-null    float64
     5   flipper_length_mm  349 non-null    float64
     6   body_mass_g        349 non-null    float64
     7   sex                340 non-null    object 
     8   year               351 non-null    int64  
    dtypes: float64(4), int64(1), object(4)
    memory usage: 24.8+ KB


The `bill_depth_mm` now has type `float64` as we originally expected.

This was a simple example with just one strange value - we'll see more approaches for handling and sanitising strings later.

## Sanity Checking Values

### Numeric Columns

The pandas `describe()` function gives summary statistics for the numeric columns in our data (the mean, standard deviation, minimum and maximum value, and quartiles for each column):


```python
df.describe()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>bill_length_mm</th>
      <th>bill_depth_mm</th>
      <th>flipper_length_mm</th>
      <th>body_mass_g</th>
      <th>year</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>347.000000</td>
      <td>349.000000</td>
      <td>349.000000</td>
      <td>349.000000</td>
      <td>351.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>43.923055</td>
      <td>17.152722</td>
      <td>200.088825</td>
      <td>4305.329513</td>
      <td>2008.022792</td>
    </tr>
    <tr>
      <th>std</th>
      <td>5.491795</td>
      <td>1.967049</td>
      <td>21.320100</td>
      <td>2256.300048</td>
      <td>0.820832</td>
    </tr>
    <tr>
      <th>min</th>
      <td>32.100000</td>
      <td>13.100000</td>
      <td>-99.000000</td>
      <td>285.000000</td>
      <td>2007.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>39.200000</td>
      <td>15.600000</td>
      <td>190.000000</td>
      <td>3550.000000</td>
      <td>2007.000000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>44.500000</td>
      <td>17.300000</td>
      <td>197.000000</td>
      <td>4050.000000</td>
      <td>2008.000000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>48.500000</td>
      <td>18.700000</td>
      <td>213.000000</td>
      <td>4775.000000</td>
      <td>2009.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>59.600000</td>
      <td>21.500000</td>
      <td>231.000000</td>
      <td>43400.000000</td>
      <td>2009.000000</td>
    </tr>
  </tbody>
</table>
</div>



Even though `bill_length_mm`, and several of the other columns, have missing (NaN) values, Pandas is able to compute statistics for that column. When calculating these Pandas will ignore all NaN values by default. To change this behaviour, some functions have a `skipna` argument, for example `df["bill_length_mm"].mean(skipna=False)` will return NaN if there are _any_ NaN values in the column.

You should think carefully about which approach is more suitable for your data (for example, if a column only has a few non-null values will the mean be representative?)


Looking at these values gives us a better idea of what our data contains, but also allows us to perform some sanity checks. For example, do the minimum and maximum values in each column make sense given what we know about the dataset?

There are two things that might standout. First, the `flipper_length_mm` column has a minimum value of -99, but all the other values in the data are positive as we'd expect for measurements of lengths, widths and weights. In some datasets missing data is represented with negative values (but this may not always be the case so, as always, make sure to check what they mean in any data you're using).

If we're sure `-99` is meant to be a missing value, we can replace those with `numpy.nan` so Pandas will treat them correctly:


```python
df = df.replace(-99, numpy.nan)
```

With these values replaced, the "actual" minimum value of `flipper_length_mm` is 172 mm:


```python
df["flipper_length_mm"].min()
```




    172.0



The second thing that may stand out is the minimum value of 285 grams in `body_mass_g`, which looks far smaller than the other values (e.g., the 25% quartile of `body_mass_g` is only 3550g). Excluding the 285g value the next lightest penguin weighs 2700g:


```python
# True for each row with body_mass_g greater than the min value of 285g
smaller_petals = df["body_mass_g"] > df["body_mass_g"].min()

# Lowest penguin weight out of all rows with weights above 285g
df.loc[smaller_petals, "body_mass_g"].min()
```




    2700.0



Another way to see this would be to sort the data frame by body mass using the [`sort_values`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.sort_values.html) function:


```python
df.sort_values(by="body_mass_g").head(10)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Id</th>
      <th>species</th>
      <th>island</th>
      <th>bill_length_mm</th>
      <th>bill_depth_mm</th>
      <th>flipper_length_mm</th>
      <th>body_mass_g</th>
      <th>sex</th>
      <th>year</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>6</th>
      <td>P-348</td>
      <td>Adelie</td>
      <td>Biscoe</td>
      <td>36.4</td>
      <td>18.1</td>
      <td>193.0</td>
      <td>285.0</td>
      <td>female</td>
      <td>2007</td>
    </tr>
    <tr>
      <th>236</th>
      <td>P-314</td>
      <td>Chinstrap</td>
      <td>Dream</td>
      <td>46.9</td>
      <td>16.6</td>
      <td>192.0</td>
      <td>2700.0</td>
      <td>female</td>
      <td>2008</td>
    </tr>
    <tr>
      <th>248</th>
      <td>P-058</td>
      <td>Adelie</td>
      <td>Biscoe</td>
      <td>36.5</td>
      <td>16.6</td>
      <td>181.0</td>
      <td>2850.0</td>
      <td>female</td>
      <td>2008</td>
    </tr>
    <tr>
      <th>311</th>
      <td>P-064</td>
      <td>Adelie</td>
      <td>Biscoe</td>
      <td>36.4</td>
      <td>17.1</td>
      <td>184.0</td>
      <td>2850.0</td>
      <td>female</td>
      <td>2008</td>
    </tr>
    <tr>
      <th>349</th>
      <td>P-098</td>
      <td>Adelie</td>
      <td>Dream</td>
      <td>33.1</td>
      <td>16.1</td>
      <td>178.0</td>
      <td>2900.0</td>
      <td>female</td>
      <td>2008</td>
    </tr>
    <tr>
      <th>227</th>
      <td>P-298</td>
      <td>Chinstrap</td>
      <td>Dream</td>
      <td>43.2</td>
      <td>16.6</td>
      <td>187.0</td>
      <td>2900.0</td>
      <td>female</td>
      <td>2007</td>
    </tr>
    <tr>
      <th>270</th>
      <td>P-116</td>
      <td>Adelie</td>
      <td>Torgersen</td>
      <td>38.6</td>
      <td>17.0</td>
      <td>188.0</td>
      <td>2900.0</td>
      <td>female</td>
      <td>2009</td>
    </tr>
    <tr>
      <th>17</th>
      <td>P-054</td>
      <td>Adelie</td>
      <td>Biscoe</td>
      <td>34.5</td>
      <td>18.1</td>
      <td>187.0</td>
      <td>2900.0</td>
      <td>female</td>
      <td>2008</td>
    </tr>
    <tr>
      <th>137</th>
      <td>P-104</td>
      <td>Adelie</td>
      <td>Biscoe</td>
      <td>37.9</td>
      <td>18.6</td>
      <td>193.0</td>
      <td>2925.0</td>
      <td>female</td>
      <td>2009</td>
    </tr>
    <tr>
      <th>337</th>
      <td>P-047</td>
      <td>Adelie</td>
      <td>Dream</td>
      <td>37.5</td>
      <td>18.9</td>
      <td>179.0</td>
      <td>2975.0</td>
      <td>NaN</td>
      <td>2007</td>
    </tr>
  </tbody>
</table>
</div>



By default `sort_values` sorts values from smallest to largest, you can change that by setting `ascending=False`. 

Again, we see the 2nd smallest value in the column is only 2700g. This could be another data entry error (perhaps the weight was meant to be 2850g rather than 285g), or perhaps that penguin is a chick and the rest are adults. This type of issue is much more nuanced and difficult to spot in real world scenarios. Visualizing the data (and distributions in the data) can be very helpful here, which is the focus of the next module.

### Text and Categorical Columns

Note that the `species`, `island`, and `sex` columns do not appear when we use `describe()` above as they contain text. For both text and numeric columns, it can be helpful to know the number of unique values in each column:


```python
df.nunique()
```




    Id                   350
    species                4
    island                 3
    bill_length_mm       164
    bill_depth_mm         80
    flipper_length_mm     55
    body_mass_g           96
    sex                    2
    year                   3
    dtype: int64



The measurement and `Id` columns have many unique values, whereas columns like `island` have only a few different unique values (categories).  Looking closely, the `species` column has four different values, but from the dataset documentation we only expect there to be three penguin species.

The `value_counts()` function, applied to the `species` column, shows the number of occurrences of the different values in that column:


```python
df["species"].value_counts()
```




    Adelie       155
    Gentoo       125
    Chinstrap     70
    UNKNOWN        1
    Name: species, dtype: int64



The "AdÃ©lie", "Chinstrap", and "Gentoo" species described in the documentation all appear, but there's also an "UNKNOWN" entry. This looks like it should have been treated as a missing value. To make Pandas correctly treat it as missing we can replace it with `numpy.nan` using the [`replace`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.replace.html?highlight=replace#pandas.DataFrame.replace) method:


```python
df["species"] = df["species"].replace("UNKNOWN", numpy.nan)
df["species"].value_counts()
```




    Adelie       155
    Gentoo       125
    Chinstrap     70
    Name: species, dtype: int64



By default, the `value_counts` will not display the number of missing values in the column. To show that you can use `df["species"].value_counts(dropna=False)` instead. You can also try `df["species"].value_counts(normalize=True)` to show the fraction of data with each value, rather than the count.

We'll look at more approaches for manipulating strings and categories in Sections [2.2.4.2](2-02-04-02-TextData) and [2.2.4.3](2-02-04-02-TextData) of this module.

Finally, it may be interesting to look at how the measurements vary between the species. We can do that with the Pandas [`groupby`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.groupby.html) function: 


```python
df.groupby("species").mean()
```

    /var/folders/xv/d5nvn2ps5r3fcf276w707n01qdmpqf/T/ipykernel_55040/2880954085.py:1: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.
      df.groupby("species").mean()





<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>bill_length_mm</th>
      <th>bill_depth_mm</th>
      <th>flipper_length_mm</th>
      <th>body_mass_g</th>
      <th>year</th>
    </tr>
    <tr>
      <th>species</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Adelie</th>
      <td>38.757516</td>
      <td>18.335714</td>
      <td>189.993464</td>
      <td>3934.805195</td>
      <td>2008.006452</td>
    </tr>
    <tr>
      <th>Chinstrap</th>
      <td>48.800000</td>
      <td>18.424286</td>
      <td>195.785714</td>
      <td>3733.571429</td>
      <td>2007.957143</td>
    </tr>
    <tr>
      <th>Gentoo</th>
      <td>47.486290</td>
      <td>14.975806</td>
      <td>217.241935</td>
      <td>5080.241935</td>
      <td>2008.072000</td>
    </tr>
  </tbody>
</table>
</div>



`df.groupby("species")` splits the date frame into sub-groups with the same value in the "species" column. We then must specify a function we want to use to summarize the members of each group, in this case the mean. It looks like, on average, "Chinstrap" penguins have the largest bills, but "Gentoo" penguins have the largest flippers and body mass. For more information about using `groupby` see [here](https://pandas.pydata.org/pandas-docs/stable/user_guide/groupby.html).

## Duplicate Data

In the output of `df.nunique()` above we see the `Id` column has 350 unique values, one fewer than the 351 rows in the dataset. We expect `Id` to be a unique identifier, so to have 351 unique values (1 for each row). What's going on?

One explanation could be that there are duplicate rows in the data. The [`duplicated`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.duplicated.html) method of a data frame returns True for any rows that appear multiple times in the data (with an exact copy of all values):


```python
df.duplicated()
```




    0      False
    1      False
    2      False
    3      False
    4      False
           ...  
    346    False
    347    False
    348    False
    349    False
    350    False
    Length: 351, dtype: bool



We can use this to filter the data frame and show only the duplicated rows:


```python
df[df.duplicated(keep=False)]
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Id</th>
      <th>species</th>
      <th>island</th>
      <th>bill_length_mm</th>
      <th>bill_depth_mm</th>
      <th>flipper_length_mm</th>
      <th>body_mass_g</th>
      <th>sex</th>
      <th>year</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>36</th>
      <td>P-276</td>
      <td>Chinstrap</td>
      <td>Dream</td>
      <td>46.5</td>
      <td>17.9</td>
      <td>192.0</td>
      <td>3500.0</td>
      <td>female</td>
      <td>2007</td>
    </tr>
    <tr>
      <th>324</th>
      <td>P-276</td>
      <td>Chinstrap</td>
      <td>Dream</td>
      <td>46.5</td>
      <td>17.9</td>
      <td>192.0</td>
      <td>3500.0</td>
      <td>female</td>
      <td>2007</td>
    </tr>
  </tbody>
</table>
</div>



By default, the `duplicated` function only marks the second and subsequent instances of the same data as being duplicates. Setting `keep=False` marks the first instance as a duplicate as well.

We see there are two entries for a penguin with id `P-276` in the data. Why might that be the case? It could be caused by a data entry/processing issue and be there by mistake, or be a genuine repeated measurement for this penguin, for example. It's important to understand the context before taking any action.

In some cases it may be appropriate to delete the duplicate data. This can be done with the [`drop_duplicates`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop_duplicates.html?highlight=drop_duplicates#pandas.DataFrame.drop_duplicates) method:


```python
print("Length before removing duplicates:", len(df), "rows")
df = df.drop_duplicates()
print("Length after removing duplicates:", len(df), "rows")
```

    Length before removing duplicates: 351 rows
    Length after removing duplicates: 350 rows


## Displaying Data Frames with Style ðŸ˜Ž

You can get fancy with how you display data frames by highlighting and formatting cells differently using its `style` attribute. There are a few examples below, for more details see the [Table Visualization page in the Pandas documentation](https://pandas.pydata.org/pandas-docs/stable/user_guide/style.html#Styler-Object-and-HTML).

Change the precision with which numbers are displayed:


```python
df_top10 = df.head(10)  # just style the first 10 rows for demo purposes here

# round values to nearest integer (0 decimal places)
df_top10.style.format(precision=0)
```




<style type="text/css">
</style>
<table id="T_5a03a">
  <thead>
    <tr>
      <th class="blank level0" >&nbsp;</th>
      <th id="T_5a03a_level0_col0" class="col_heading level0 col0" >Id</th>
      <th id="T_5a03a_level0_col1" class="col_heading level0 col1" >species</th>
      <th id="T_5a03a_level0_col2" class="col_heading level0 col2" >island</th>
      <th id="T_5a03a_level0_col3" class="col_heading level0 col3" >bill_length_mm</th>
      <th id="T_5a03a_level0_col4" class="col_heading level0 col4" >bill_depth_mm</th>
      <th id="T_5a03a_level0_col5" class="col_heading level0 col5" >flipper_length_mm</th>
      <th id="T_5a03a_level0_col6" class="col_heading level0 col6" >body_mass_g</th>
      <th id="T_5a03a_level0_col7" class="col_heading level0 col7" >sex</th>
      <th id="T_5a03a_level0_col8" class="col_heading level0 col8" >year</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th id="T_5a03a_level0_row0" class="row_heading level0 row0" >0</th>
      <td id="T_5a03a_row0_col0" class="data row0 col0" >P-179</td>
      <td id="T_5a03a_row0_col1" class="data row0 col1" >Gentoo</td>
      <td id="T_5a03a_row0_col2" class="data row0 col2" >Biscoe</td>
      <td id="T_5a03a_row0_col3" class="data row0 col3" >48</td>
      <td id="T_5a03a_row0_col4" class="data row0 col4" >15</td>
      <td id="T_5a03a_row0_col5" class="data row0 col5" >215</td>
      <td id="T_5a03a_row0_col6" class="data row0 col6" >5650</td>
      <td id="T_5a03a_row0_col7" class="data row0 col7" >male</td>
      <td id="T_5a03a_row0_col8" class="data row0 col8" >2007</td>
    </tr>
    <tr>
      <th id="T_5a03a_level0_row1" class="row_heading level0 row1" >1</th>
      <td id="T_5a03a_row1_col0" class="data row1 col0" >P-306</td>
      <td id="T_5a03a_row1_col1" class="data row1 col1" >Chinstrap</td>
      <td id="T_5a03a_row1_col2" class="data row1 col2" >Dream</td>
      <td id="T_5a03a_row1_col3" class="data row1 col3" >41</td>
      <td id="T_5a03a_row1_col4" class="data row1 col4" >17</td>
      <td id="T_5a03a_row1_col5" class="data row1 col5" >187</td>
      <td id="T_5a03a_row1_col6" class="data row1 col6" >3200</td>
      <td id="T_5a03a_row1_col7" class="data row1 col7" >female</td>
      <td id="T_5a03a_row1_col8" class="data row1 col8" >2008</td>
    </tr>
    <tr>
      <th id="T_5a03a_level0_row2" class="row_heading level0 row2" >2</th>
      <td id="T_5a03a_row2_col0" class="data row2 col0" >P-247</td>
      <td id="T_5a03a_row2_col1" class="data row2 col1" >Gentoo</td>
      <td id="T_5a03a_row2_col2" class="data row2 col2" >Biscoe</td>
      <td id="T_5a03a_row2_col3" class="data row2 col3" >51</td>
      <td id="T_5a03a_row2_col4" class="data row2 col4" >16</td>
      <td id="T_5a03a_row2_col5" class="data row2 col5" >226</td>
      <td id="T_5a03a_row2_col6" class="data row2 col6" >5200</td>
      <td id="T_5a03a_row2_col7" class="data row2 col7" >male</td>
      <td id="T_5a03a_row2_col8" class="data row2 col8" >2009</td>
    </tr>
    <tr>
      <th id="T_5a03a_level0_row3" class="row_heading level0 row3" >3</th>
      <td id="T_5a03a_row3_col0" class="data row3 col0" >P-120</td>
      <td id="T_5a03a_row3_col1" class="data row3 col1" >Adelie</td>
      <td id="T_5a03a_row3_col2" class="data row3 col2" >Torgersen</td>
      <td id="T_5a03a_row3_col3" class="data row3 col3" >36</td>
      <td id="T_5a03a_row3_col4" class="data row3 col4" >17</td>
      <td id="T_5a03a_row3_col5" class="data row3 col5" >187</td>
      <td id="T_5a03a_row3_col6" class="data row3 col6" >3150</td>
      <td id="T_5a03a_row3_col7" class="data row3 col7" >female</td>
      <td id="T_5a03a_row3_col8" class="data row3 col8" >2009</td>
    </tr>
    <tr>
      <th id="T_5a03a_level0_row4" class="row_heading level0 row4" >4</th>
      <td id="T_5a03a_row4_col0" class="data row4 col0" >P-220</td>
      <td id="T_5a03a_row4_col1" class="data row4 col1" >Gentoo</td>
      <td id="T_5a03a_row4_col2" class="data row4 col2" >Biscoe</td>
      <td id="T_5a03a_row4_col3" class="data row4 col3" >44</td>
      <td id="T_5a03a_row4_col4" class="data row4 col4" >14</td>
      <td id="T_5a03a_row4_col5" class="data row4 col5" >220</td>
      <td id="T_5a03a_row4_col6" class="data row4 col6" >4700</td>
      <td id="T_5a03a_row4_col7" class="data row4 col7" >female</td>
      <td id="T_5a03a_row4_col8" class="data row4 col8" >2008</td>
    </tr>
    <tr>
      <th id="T_5a03a_level0_row5" class="row_heading level0 row5" >5</th>
      <td id="T_5a03a_row5_col0" class="data row5 col0" >P-150</td>
      <td id="T_5a03a_row5_col1" class="data row5 col1" >Adelie</td>
      <td id="T_5a03a_row5_col2" class="data row5 col2" >Dream</td>
      <td id="T_5a03a_row5_col3" class="data row5 col3" >36</td>
      <td id="T_5a03a_row5_col4" class="data row5 col4" >17</td>
      <td id="T_5a03a_row5_col5" class="data row5 col5" >187</td>
      <td id="T_5a03a_row5_col6" class="data row5 col6" >3700</td>
      <td id="T_5a03a_row5_col7" class="data row5 col7" >female</td>
      <td id="T_5a03a_row5_col8" class="data row5 col8" >2009</td>
    </tr>
    <tr>
      <th id="T_5a03a_level0_row6" class="row_heading level0 row6" >6</th>
      <td id="T_5a03a_row6_col0" class="data row6 col0" >P-348</td>
      <td id="T_5a03a_row6_col1" class="data row6 col1" >Adelie</td>
      <td id="T_5a03a_row6_col2" class="data row6 col2" >Biscoe</td>
      <td id="T_5a03a_row6_col3" class="data row6 col3" >36</td>
      <td id="T_5a03a_row6_col4" class="data row6 col4" >18</td>
      <td id="T_5a03a_row6_col5" class="data row6 col5" >193</td>
      <td id="T_5a03a_row6_col6" class="data row6 col6" >285</td>
      <td id="T_5a03a_row6_col7" class="data row6 col7" >female</td>
      <td id="T_5a03a_row6_col8" class="data row6 col8" >2007</td>
    </tr>
    <tr>
      <th id="T_5a03a_level0_row7" class="row_heading level0 row7" >7</th>
      <td id="T_5a03a_row7_col0" class="data row7 col0" >P-091</td>
      <td id="T_5a03a_row7_col1" class="data row7 col1" >Adelie</td>
      <td id="T_5a03a_row7_col2" class="data row7 col2" >Dream</td>
      <td id="T_5a03a_row7_col3" class="data row7 col3" >41</td>
      <td id="T_5a03a_row7_col4" class="data row7 col4" >18</td>
      <td id="T_5a03a_row7_col5" class="data row7 col5" >205</td>
      <td id="T_5a03a_row7_col6" class="data row7 col6" >4300</td>
      <td id="T_5a03a_row7_col7" class="data row7 col7" >male</td>
      <td id="T_5a03a_row7_col8" class="data row7 col8" >2008</td>
    </tr>
    <tr>
      <th id="T_5a03a_level0_row8" class="row_heading level0 row8" >8</th>
      <td id="T_5a03a_row8_col0" class="data row8 col0" >P-327</td>
      <td id="T_5a03a_row8_col1" class="data row8 col1" >Chinstrap</td>
      <td id="T_5a03a_row8_col2" class="data row8 col2" >Dream</td>
      <td id="T_5a03a_row8_col3" class="data row8 col3" >51</td>
      <td id="T_5a03a_row8_col4" class="data row8 col4" >19</td>
      <td id="T_5a03a_row8_col5" class="data row8 col5" >201</td>
      <td id="T_5a03a_row8_col6" class="data row8 col6" >3950</td>
      <td id="T_5a03a_row8_col7" class="data row8 col7" >male</td>
      <td id="T_5a03a_row8_col8" class="data row8 col8" >2009</td>
    </tr>
    <tr>
      <th id="T_5a03a_level0_row9" class="row_heading level0 row9" >9</th>
      <td id="T_5a03a_row9_col0" class="data row9 col0" >P-221</td>
      <td id="T_5a03a_row9_col1" class="data row9 col1" >Gentoo</td>
      <td id="T_5a03a_row9_col2" class="data row9 col2" >Biscoe</td>
      <td id="T_5a03a_row9_col3" class="data row9 col3" >51</td>
      <td id="T_5a03a_row9_col4" class="data row9 col4" >15</td>
      <td id="T_5a03a_row9_col5" class="data row9 col5" >223</td>
      <td id="T_5a03a_row9_col6" class="data row9 col6" >5550</td>
      <td id="T_5a03a_row9_col7" class="data row9 col7" >male</td>
      <td id="T_5a03a_row9_col8" class="data row9 col8" >2008</td>
    </tr>
  </tbody>
</table>




Apply a colour gradient to each column based on each cell's value:


```python
df_top10.style.background_gradient()
```




<style type="text/css">
#T_20f12_row0_col3 {
  background-color: #056dab;
  color: #f1f1f1;
}
#T_20f12_row0_col4, #T_20f12_row9_col4 {
  background-color: #e3e0ee;
  color: #000000;
}
#T_20f12_row0_col5 {
  background-color: #1278b4;
  color: #f1f1f1;
}
#T_20f12_row0_col6, #T_20f12_row2_col5, #T_20f12_row2_col8, #T_20f12_row3_col8, #T_20f12_row5_col8, #T_20f12_row8_col3, #T_20f12_row8_col4, #T_20f12_row8_col8 {
  background-color: #023858;
  color: #f1f1f1;
}
#T_20f12_row0_col8, #T_20f12_row1_col5, #T_20f12_row3_col5, #T_20f12_row4_col4, #T_20f12_row5_col3, #T_20f12_row5_col5, #T_20f12_row6_col6, #T_20f12_row6_col8 {
  background-color: #fff7fb;
  color: #000000;
}
#T_20f12_row1_col3 {
  background-color: #b9c6e0;
  color: #000000;
}
#T_20f12_row1_col4, #T_20f12_row1_col8, #T_20f12_row4_col8, #T_20f12_row7_col8, #T_20f12_row9_col8 {
  background-color: #73a9cf;
  color: #f1f1f1;
}
#T_20f12_row1_col6 {
  background-color: #5ea0ca;
  color: #f1f1f1;
}
#T_20f12_row2_col3 {
  background-color: #034267;
  color: #f1f1f1;
}
#T_20f12_row2_col4 {
  background-color: #bcc7e1;
  color: #000000;
}
#T_20f12_row2_col6 {
  background-color: #034e7b;
  color: #f1f1f1;
}
#T_20f12_row3_col3 {
  background-color: #fdf5fa;
  color: #000000;
}
#T_20f12_row3_col4 {
  background-color: #3790c0;
  color: #f1f1f1;
}
#T_20f12_row3_col6 {
  background-color: #63a2cb;
  color: #f1f1f1;
}
#T_20f12_row4_col3 {
  background-color: #79abd0;
  color: #f1f1f1;
}
#T_20f12_row4_col5 {
  background-color: #045f95;
  color: #f1f1f1;
}
#T_20f12_row4_col6 {
  background-color: #04639b;
  color: #f1f1f1;
}
#T_20f12_row5_col4 {
  background-color: #4094c3;
  color: #f1f1f1;
}
#T_20f12_row5_col6 {
  background-color: #328dbf;
  color: #f1f1f1;
}
#T_20f12_row6_col3 {
  background-color: #fbf4f9;
  color: #000000;
}
#T_20f12_row6_col4, #T_20f12_row7_col4 {
  background-color: #04649e;
  color: #f1f1f1;
}
#T_20f12_row6_col5 {
  background-color: #e6e2ef;
  color: #000000;
}
#T_20f12_row7_col3 {
  background-color: #b5c4df;
  color: #000000;
}
#T_20f12_row7_col5 {
  background-color: #83afd3;
  color: #f1f1f1;
}
#T_20f12_row7_col6 {
  background-color: #0570b0;
  color: #f1f1f1;
}
#T_20f12_row8_col5 {
  background-color: #acc0dd;
  color: #000000;
}
#T_20f12_row8_col6 {
  background-color: #2081b9;
  color: #f1f1f1;
}
#T_20f12_row9_col3 {
  background-color: #03446a;
  color: #f1f1f1;
}
#T_20f12_row9_col5 {
  background-color: #034c78;
  color: #f1f1f1;
}
#T_20f12_row9_col6 {
  background-color: #023c5f;
  color: #f1f1f1;
}
</style>
<table id="T_20f12">
  <thead>
    <tr>
      <th class="blank level0" >&nbsp;</th>
      <th id="T_20f12_level0_col0" class="col_heading level0 col0" >Id</th>
      <th id="T_20f12_level0_col1" class="col_heading level0 col1" >species</th>
      <th id="T_20f12_level0_col2" class="col_heading level0 col2" >island</th>
      <th id="T_20f12_level0_col3" class="col_heading level0 col3" >bill_length_mm</th>
      <th id="T_20f12_level0_col4" class="col_heading level0 col4" >bill_depth_mm</th>
      <th id="T_20f12_level0_col5" class="col_heading level0 col5" >flipper_length_mm</th>
      <th id="T_20f12_level0_col6" class="col_heading level0 col6" >body_mass_g</th>
      <th id="T_20f12_level0_col7" class="col_heading level0 col7" >sex</th>
      <th id="T_20f12_level0_col8" class="col_heading level0 col8" >year</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th id="T_20f12_level0_row0" class="row_heading level0 row0" >0</th>
      <td id="T_20f12_row0_col0" class="data row0 col0" >P-179</td>
      <td id="T_20f12_row0_col1" class="data row0 col1" >Gentoo</td>
      <td id="T_20f12_row0_col2" class="data row0 col2" >Biscoe</td>
      <td id="T_20f12_row0_col3" class="data row0 col3" >47.800000</td>
      <td id="T_20f12_row0_col4" class="data row0 col4" >15.000000</td>
      <td id="T_20f12_row0_col5" class="data row0 col5" >215.000000</td>
      <td id="T_20f12_row0_col6" class="data row0 col6" >5650.000000</td>
      <td id="T_20f12_row0_col7" class="data row0 col7" >male</td>
      <td id="T_20f12_row0_col8" class="data row0 col8" >2007</td>
    </tr>
    <tr>
      <th id="T_20f12_level0_row1" class="row_heading level0 row1" >1</th>
      <td id="T_20f12_row1_col0" class="data row1 col0" >P-306</td>
      <td id="T_20f12_row1_col1" class="data row1 col1" >Chinstrap</td>
      <td id="T_20f12_row1_col2" class="data row1 col2" >Dream</td>
      <td id="T_20f12_row1_col3" class="data row1 col3" >40.900000</td>
      <td id="T_20f12_row1_col4" class="data row1 col4" >16.600000</td>
      <td id="T_20f12_row1_col5" class="data row1 col5" >187.000000</td>
      <td id="T_20f12_row1_col6" class="data row1 col6" >3200.000000</td>
      <td id="T_20f12_row1_col7" class="data row1 col7" >female</td>
      <td id="T_20f12_row1_col8" class="data row1 col8" >2008</td>
    </tr>
    <tr>
      <th id="T_20f12_level0_row2" class="row_heading level0 row2" >2</th>
      <td id="T_20f12_row2_col0" class="data row2 col0" >P-247</td>
      <td id="T_20f12_row2_col1" class="data row2 col1" >Gentoo</td>
      <td id="T_20f12_row2_col2" class="data row2 col2" >Biscoe</td>
      <td id="T_20f12_row2_col3" class="data row2 col3" >50.800000</td>
      <td id="T_20f12_row2_col4" class="data row2 col4" >15.700000</td>
      <td id="T_20f12_row2_col5" class="data row2 col5" >226.000000</td>
      <td id="T_20f12_row2_col6" class="data row2 col6" >5200.000000</td>
      <td id="T_20f12_row2_col7" class="data row2 col7" >male</td>
      <td id="T_20f12_row2_col8" class="data row2 col8" >2009</td>
    </tr>
    <tr>
      <th id="T_20f12_level0_row3" class="row_heading level0 row3" >3</th>
      <td id="T_20f12_row3_col0" class="data row3 col0" >P-120</td>
      <td id="T_20f12_row3_col1" class="data row3 col1" >Adelie</td>
      <td id="T_20f12_row3_col2" class="data row3 col2" >Torgersen</td>
      <td id="T_20f12_row3_col3" class="data row3 col3" >36.200000</td>
      <td id="T_20f12_row3_col4" class="data row3 col4" >17.200000</td>
      <td id="T_20f12_row3_col5" class="data row3 col5" >187.000000</td>
      <td id="T_20f12_row3_col6" class="data row3 col6" >3150.000000</td>
      <td id="T_20f12_row3_col7" class="data row3 col7" >female</td>
      <td id="T_20f12_row3_col8" class="data row3 col8" >2009</td>
    </tr>
    <tr>
      <th id="T_20f12_level0_row4" class="row_heading level0 row4" >4</th>
      <td id="T_20f12_row4_col0" class="data row4 col0" >P-220</td>
      <td id="T_20f12_row4_col1" class="data row4 col1" >Gentoo</td>
      <td id="T_20f12_row4_col2" class="data row4 col2" >Biscoe</td>
      <td id="T_20f12_row4_col3" class="data row4 col3" >43.500000</td>
      <td id="T_20f12_row4_col4" class="data row4 col4" >14.200000</td>
      <td id="T_20f12_row4_col5" class="data row4 col5" >220.000000</td>
      <td id="T_20f12_row4_col6" class="data row4 col6" >4700.000000</td>
      <td id="T_20f12_row4_col7" class="data row4 col7" >female</td>
      <td id="T_20f12_row4_col8" class="data row4 col8" >2008</td>
    </tr>
    <tr>
      <th id="T_20f12_level0_row5" class="row_heading level0 row5" >5</th>
      <td id="T_20f12_row5_col0" class="data row5 col0" >P-150</td>
      <td id="T_20f12_row5_col1" class="data row5 col1" >Adelie</td>
      <td id="T_20f12_row5_col2" class="data row5 col2" >Dream</td>
      <td id="T_20f12_row5_col3" class="data row5 col3" >36.000000</td>
      <td id="T_20f12_row5_col4" class="data row5 col4" >17.100000</td>
      <td id="T_20f12_row5_col5" class="data row5 col5" >187.000000</td>
      <td id="T_20f12_row5_col6" class="data row5 col6" >3700.000000</td>
      <td id="T_20f12_row5_col7" class="data row5 col7" >female</td>
      <td id="T_20f12_row5_col8" class="data row5 col8" >2009</td>
    </tr>
    <tr>
      <th id="T_20f12_level0_row6" class="row_heading level0 row6" >6</th>
      <td id="T_20f12_row6_col0" class="data row6 col0" >P-348</td>
      <td id="T_20f12_row6_col1" class="data row6 col1" >Adelie</td>
      <td id="T_20f12_row6_col2" class="data row6 col2" >Biscoe</td>
      <td id="T_20f12_row6_col3" class="data row6 col3" >36.400000</td>
      <td id="T_20f12_row6_col4" class="data row6 col4" >18.100000</td>
      <td id="T_20f12_row6_col5" class="data row6 col5" >193.000000</td>
      <td id="T_20f12_row6_col6" class="data row6 col6" >285.000000</td>
      <td id="T_20f12_row6_col7" class="data row6 col7" >female</td>
      <td id="T_20f12_row6_col8" class="data row6 col8" >2007</td>
    </tr>
    <tr>
      <th id="T_20f12_level0_row7" class="row_heading level0 row7" >7</th>
      <td id="T_20f12_row7_col0" class="data row7 col0" >P-091</td>
      <td id="T_20f12_row7_col1" class="data row7 col1" >Adelie</td>
      <td id="T_20f12_row7_col2" class="data row7 col2" >Dream</td>
      <td id="T_20f12_row7_col3" class="data row7 col3" >41.100000</td>
      <td id="T_20f12_row7_col4" class="data row7 col4" >18.100000</td>
      <td id="T_20f12_row7_col5" class="data row7 col5" >205.000000</td>
      <td id="T_20f12_row7_col6" class="data row7 col6" >4300.000000</td>
      <td id="T_20f12_row7_col7" class="data row7 col7" >male</td>
      <td id="T_20f12_row7_col8" class="data row7 col8" >2008</td>
    </tr>
    <tr>
      <th id="T_20f12_level0_row8" class="row_heading level0 row8" >8</th>
      <td id="T_20f12_row8_col0" class="data row8 col0" >P-327</td>
      <td id="T_20f12_row8_col1" class="data row8 col1" >Chinstrap</td>
      <td id="T_20f12_row8_col2" class="data row8 col2" >Dream</td>
      <td id="T_20f12_row8_col3" class="data row8 col3" >51.400000</td>
      <td id="T_20f12_row8_col4" class="data row8 col4" >19.000000</td>
      <td id="T_20f12_row8_col5" class="data row8 col5" >201.000000</td>
      <td id="T_20f12_row8_col6" class="data row8 col6" >3950.000000</td>
      <td id="T_20f12_row8_col7" class="data row8 col7" >male</td>
      <td id="T_20f12_row8_col8" class="data row8 col8" >2009</td>
    </tr>
    <tr>
      <th id="T_20f12_level0_row9" class="row_heading level0 row9" >9</th>
      <td id="T_20f12_row9_col0" class="data row9 col0" >P-221</td>
      <td id="T_20f12_row9_col1" class="data row9 col1" >Gentoo</td>
      <td id="T_20f12_row9_col2" class="data row9 col2" >Biscoe</td>
      <td id="T_20f12_row9_col3" class="data row9 col3" >50.700000</td>
      <td id="T_20f12_row9_col4" class="data row9 col4" >15.000000</td>
      <td id="T_20f12_row9_col5" class="data row9 col5" >223.000000</td>
      <td id="T_20f12_row9_col6" class="data row9 col6" >5550.000000</td>
      <td id="T_20f12_row9_col7" class="data row9 col7" >male</td>
      <td id="T_20f12_row9_col8" class="data row9 col8" >2008</td>
    </tr>
  </tbody>
</table>




Highlight the smallest value in each column:


```python
df_top10.style.highlight_min()
```




<style type="text/css">
#T_9c679_row0_col2, #T_9c679_row0_col8, #T_9c679_row1_col5, #T_9c679_row1_col7, #T_9c679_row2_col2, #T_9c679_row3_col1, #T_9c679_row3_col5, #T_9c679_row3_col7, #T_9c679_row4_col2, #T_9c679_row4_col4, #T_9c679_row4_col7, #T_9c679_row5_col1, #T_9c679_row5_col3, #T_9c679_row5_col5, #T_9c679_row5_col7, #T_9c679_row6_col1, #T_9c679_row6_col2, #T_9c679_row6_col6, #T_9c679_row6_col7, #T_9c679_row6_col8, #T_9c679_row7_col0, #T_9c679_row7_col1, #T_9c679_row9_col2 {
  background-color: yellow;
}
</style>
<table id="T_9c679">
  <thead>
    <tr>
      <th class="blank level0" >&nbsp;</th>
      <th id="T_9c679_level0_col0" class="col_heading level0 col0" >Id</th>
      <th id="T_9c679_level0_col1" class="col_heading level0 col1" >species</th>
      <th id="T_9c679_level0_col2" class="col_heading level0 col2" >island</th>
      <th id="T_9c679_level0_col3" class="col_heading level0 col3" >bill_length_mm</th>
      <th id="T_9c679_level0_col4" class="col_heading level0 col4" >bill_depth_mm</th>
      <th id="T_9c679_level0_col5" class="col_heading level0 col5" >flipper_length_mm</th>
      <th id="T_9c679_level0_col6" class="col_heading level0 col6" >body_mass_g</th>
      <th id="T_9c679_level0_col7" class="col_heading level0 col7" >sex</th>
      <th id="T_9c679_level0_col8" class="col_heading level0 col8" >year</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th id="T_9c679_level0_row0" class="row_heading level0 row0" >0</th>
      <td id="T_9c679_row0_col0" class="data row0 col0" >P-179</td>
      <td id="T_9c679_row0_col1" class="data row0 col1" >Gentoo</td>
      <td id="T_9c679_row0_col2" class="data row0 col2" >Biscoe</td>
      <td id="T_9c679_row0_col3" class="data row0 col3" >47.800000</td>
      <td id="T_9c679_row0_col4" class="data row0 col4" >15.000000</td>
      <td id="T_9c679_row0_col5" class="data row0 col5" >215.000000</td>
      <td id="T_9c679_row0_col6" class="data row0 col6" >5650.000000</td>
      <td id="T_9c679_row0_col7" class="data row0 col7" >male</td>
      <td id="T_9c679_row0_col8" class="data row0 col8" >2007</td>
    </tr>
    <tr>
      <th id="T_9c679_level0_row1" class="row_heading level0 row1" >1</th>
      <td id="T_9c679_row1_col0" class="data row1 col0" >P-306</td>
      <td id="T_9c679_row1_col1" class="data row1 col1" >Chinstrap</td>
      <td id="T_9c679_row1_col2" class="data row1 col2" >Dream</td>
      <td id="T_9c679_row1_col3" class="data row1 col3" >40.900000</td>
      <td id="T_9c679_row1_col4" class="data row1 col4" >16.600000</td>
      <td id="T_9c679_row1_col5" class="data row1 col5" >187.000000</td>
      <td id="T_9c679_row1_col6" class="data row1 col6" >3200.000000</td>
      <td id="T_9c679_row1_col7" class="data row1 col7" >female</td>
      <td id="T_9c679_row1_col8" class="data row1 col8" >2008</td>
    </tr>
    <tr>
      <th id="T_9c679_level0_row2" class="row_heading level0 row2" >2</th>
      <td id="T_9c679_row2_col0" class="data row2 col0" >P-247</td>
      <td id="T_9c679_row2_col1" class="data row2 col1" >Gentoo</td>
      <td id="T_9c679_row2_col2" class="data row2 col2" >Biscoe</td>
      <td id="T_9c679_row2_col3" class="data row2 col3" >50.800000</td>
      <td id="T_9c679_row2_col4" class="data row2 col4" >15.700000</td>
      <td id="T_9c679_row2_col5" class="data row2 col5" >226.000000</td>
      <td id="T_9c679_row2_col6" class="data row2 col6" >5200.000000</td>
      <td id="T_9c679_row2_col7" class="data row2 col7" >male</td>
      <td id="T_9c679_row2_col8" class="data row2 col8" >2009</td>
    </tr>
    <tr>
      <th id="T_9c679_level0_row3" class="row_heading level0 row3" >3</th>
      <td id="T_9c679_row3_col0" class="data row3 col0" >P-120</td>
      <td id="T_9c679_row3_col1" class="data row3 col1" >Adelie</td>
      <td id="T_9c679_row3_col2" class="data row3 col2" >Torgersen</td>
      <td id="T_9c679_row3_col3" class="data row3 col3" >36.200000</td>
      <td id="T_9c679_row3_col4" class="data row3 col4" >17.200000</td>
      <td id="T_9c679_row3_col5" class="data row3 col5" >187.000000</td>
      <td id="T_9c679_row3_col6" class="data row3 col6" >3150.000000</td>
      <td id="T_9c679_row3_col7" class="data row3 col7" >female</td>
      <td id="T_9c679_row3_col8" class="data row3 col8" >2009</td>
    </tr>
    <tr>
      <th id="T_9c679_level0_row4" class="row_heading level0 row4" >4</th>
      <td id="T_9c679_row4_col0" class="data row4 col0" >P-220</td>
      <td id="T_9c679_row4_col1" class="data row4 col1" >Gentoo</td>
      <td id="T_9c679_row4_col2" class="data row4 col2" >Biscoe</td>
      <td id="T_9c679_row4_col3" class="data row4 col3" >43.500000</td>
      <td id="T_9c679_row4_col4" class="data row4 col4" >14.200000</td>
      <td id="T_9c679_row4_col5" class="data row4 col5" >220.000000</td>
      <td id="T_9c679_row4_col6" class="data row4 col6" >4700.000000</td>
      <td id="T_9c679_row4_col7" class="data row4 col7" >female</td>
      <td id="T_9c679_row4_col8" class="data row4 col8" >2008</td>
    </tr>
    <tr>
      <th id="T_9c679_level0_row5" class="row_heading level0 row5" >5</th>
      <td id="T_9c679_row5_col0" class="data row5 col0" >P-150</td>
      <td id="T_9c679_row5_col1" class="data row5 col1" >Adelie</td>
      <td id="T_9c679_row5_col2" class="data row5 col2" >Dream</td>
      <td id="T_9c679_row5_col3" class="data row5 col3" >36.000000</td>
      <td id="T_9c679_row5_col4" class="data row5 col4" >17.100000</td>
      <td id="T_9c679_row5_col5" class="data row5 col5" >187.000000</td>
      <td id="T_9c679_row5_col6" class="data row5 col6" >3700.000000</td>
      <td id="T_9c679_row5_col7" class="data row5 col7" >female</td>
      <td id="T_9c679_row5_col8" class="data row5 col8" >2009</td>
    </tr>
    <tr>
      <th id="T_9c679_level0_row6" class="row_heading level0 row6" >6</th>
      <td id="T_9c679_row6_col0" class="data row6 col0" >P-348</td>
      <td id="T_9c679_row6_col1" class="data row6 col1" >Adelie</td>
      <td id="T_9c679_row6_col2" class="data row6 col2" >Biscoe</td>
      <td id="T_9c679_row6_col3" class="data row6 col3" >36.400000</td>
      <td id="T_9c679_row6_col4" class="data row6 col4" >18.100000</td>
      <td id="T_9c679_row6_col5" class="data row6 col5" >193.000000</td>
      <td id="T_9c679_row6_col6" class="data row6 col6" >285.000000</td>
      <td id="T_9c679_row6_col7" class="data row6 col7" >female</td>
      <td id="T_9c679_row6_col8" class="data row6 col8" >2007</td>
    </tr>
    <tr>
      <th id="T_9c679_level0_row7" class="row_heading level0 row7" >7</th>
      <td id="T_9c679_row7_col0" class="data row7 col0" >P-091</td>
      <td id="T_9c679_row7_col1" class="data row7 col1" >Adelie</td>
      <td id="T_9c679_row7_col2" class="data row7 col2" >Dream</td>
      <td id="T_9c679_row7_col3" class="data row7 col3" >41.100000</td>
      <td id="T_9c679_row7_col4" class="data row7 col4" >18.100000</td>
      <td id="T_9c679_row7_col5" class="data row7 col5" >205.000000</td>
      <td id="T_9c679_row7_col6" class="data row7 col6" >4300.000000</td>
      <td id="T_9c679_row7_col7" class="data row7 col7" >male</td>
      <td id="T_9c679_row7_col8" class="data row7 col8" >2008</td>
    </tr>
    <tr>
      <th id="T_9c679_level0_row8" class="row_heading level0 row8" >8</th>
      <td id="T_9c679_row8_col0" class="data row8 col0" >P-327</td>
      <td id="T_9c679_row8_col1" class="data row8 col1" >Chinstrap</td>
      <td id="T_9c679_row8_col2" class="data row8 col2" >Dream</td>
      <td id="T_9c679_row8_col3" class="data row8 col3" >51.400000</td>
      <td id="T_9c679_row8_col4" class="data row8 col4" >19.000000</td>
      <td id="T_9c679_row8_col5" class="data row8 col5" >201.000000</td>
      <td id="T_9c679_row8_col6" class="data row8 col6" >3950.000000</td>
      <td id="T_9c679_row8_col7" class="data row8 col7" >male</td>
      <td id="T_9c679_row8_col8" class="data row8 col8" >2009</td>
    </tr>
    <tr>
      <th id="T_9c679_level0_row9" class="row_heading level0 row9" >9</th>
      <td id="T_9c679_row9_col0" class="data row9 col0" >P-221</td>
      <td id="T_9c679_row9_col1" class="data row9 col1" >Gentoo</td>
      <td id="T_9c679_row9_col2" class="data row9 col2" >Biscoe</td>
      <td id="T_9c679_row9_col3" class="data row9 col3" >50.700000</td>
      <td id="T_9c679_row9_col4" class="data row9 col4" >15.000000</td>
      <td id="T_9c679_row9_col5" class="data row9 col5" >223.000000</td>
      <td id="T_9c679_row9_col6" class="data row9 col6" >5550.000000</td>
      <td id="T_9c679_row9_col7" class="data row9 col7" >male</td>
      <td id="T_9c679_row9_col8" class="data row9 col8" >2008</td>
    </tr>
  </tbody>
</table>



