[tool.poetry]
name = "reginald-slack"
version = "0.1.0"
description = "A Slack bot for REG Hack Week 2023"
authors = ["evelinag <evelina@evelinag.com>",
           "James Robinson <jrobinson@turing.ac.uk>",
           "Ryan Chan <rchan@turing.ac.uk>",
           "Rosie Wood <rwood@turing.ac.uk>",
           "Markus Hauru <mhauru@turing.ac.uk>",
           "May Yong <myong@turing.ac.uk>",
           "James Bishop <jbishop@turing.ac.uk>",
           "Tomas Lazauskas <tlazauskas@turing.ac.uk>",
           "David Beavan <dbeavan@turing.ac.uk>",
           "Levan Bokeria <lbokeria@turing.ac.uk>",
           "Martin O'Reilly <moreilly@turing.ac.uk>"]
readme = "README.md"

[tool.poetry.dependencies]
python = "^3.11"
datasets = { version="^2.12.0", optional=true }
faiss-cpu = { version="^1.7.4", optional=true }
fastapi = { version="^0.103.1", optional=true }
gitpython = { version="^3.1.36", optional=true }
langchain = { version="^0.0.294", optional=true }
llama-index = { version="^0.8.29.post1", optional=true }
llama-hub = { version="^0.0.31", optional=true}
openai = { version="^0.27.8", optional=true }
pandas = { version="^2.0.2", optional=true }
pulumi = { version="^3.70.0", optional=true }
pulumi-azure-native = { version="^1.103.0", optional=true }
slack-sdk = { version ="^3.21.3", optional=true }
torch = [
  { version = "^2.0.1", markers = "sys_platform != 'linux'", source = "PyPI", optional=true },
  { version = "^2.0.1+cpu", markers = "sys_platform == 'linux'", source = "torchcpu", optional=true }
]
transformers = { version="=4.30.2", optional=true }
uvicorn = { version="^0.23.2", optional=true }

[tool.poetry.group.dev.dependencies]
black = "^23.3.0"
isort = "^5.12.0"
pre-commit = "^3.3.2"

[tool.poetry.extras]
api_bot = [
    "fastapi",
    "gitpython",
    "langchain",
    "llama_hub",
    "llama_index",
    "nest_asyncio",
    "pydantic",
    "openai",
    "pandas",
    "requests",
    "slack_sdk",
    "uvicorn",
]
azure = [
    "pulumi",
    "pulumi-azure-native",
]
bot = [
    "gitpython",
    "langchain",
    "llama_hub",
    "llama_index",
    "nest_asyncio",
    "openai",
    "pandas",
    "requests",
    "slack_sdk",
]
ft_notebooks = [
    "datasets",
    "faiss-cpu",
    "torch",
    "transformers",
]
llama_index_notebooks = [
    "gitpython",
    "gradio",
    "langchain",
    "llama_hub",
    "llama_index",
    "nest_asyncio",
    "pandas",
    "torch",
    "transformers",
]

[[tool.poetry.source]]
name = "PyPI"
priority = "primary"

[[tool.poetry.source]]
name = "torchcpu"
url = "https://download.pytorch.org/whl/cpu/"
priority = "explicit"


[build-system]
requires = ["poetry-core"]
build-backend = "poetry.core.masonry.api"
