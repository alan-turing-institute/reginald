{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions and Answers using Llama 2\n",
    "\n",
    "Model: Llama 2 7b-chat\n",
    "\n",
    "Data: Handbook test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kgoldmann/Documents/Projects/reginald/.venv/lib/python3.11/site-packages/pydantic/_internal/_fields.py:160: UserWarning: Field \"model_id\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from reginald.models.setup_llm import setup_llm\n",
    "\n",
    "from reginald.models.models.llama_index import (\n",
    "    setup_settings,\n",
    "    LlamaIndexLlamaCPP,\n",
    "    set_global_tokenizer,\n",
    "    compute_default_chunk_size,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.evaluation import DatasetGenerator, RelevancyEvaluator\n",
    "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex, Response\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.llms.ollama import Ollama\n",
    "\n",
    "from llama_index.core import (\n",
    "    StorageContext,\n",
    "    load_index_from_storage,\n",
    ")\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use ollama\n",
    "ollama_llm = Ollama(model=\"llama2:7b-chat\", request_timeout=60.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = compute_default_chunk_size(\n",
    "    max_input_size=4096, k=3\n",
    ")  # calculate chunk size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"meta-llama/Llama-2-7b-chat-hf\"\n",
    ").encode  # load tokenizer\n",
    "set_global_tokenizer(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = setup_settings(\n",
    "    llm=ollama_llm,\n",
    "    max_input_size=4096,\n",
    "    num_output=512,\n",
    "    chunk_overlap_ratio=0.1,\n",
    "    chunk_size=chunk_size,\n",
    "    k=3,\n",
    "    tokenizer=tokenizer,\n",
    ")  # these are settings for the storage context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To load in the handbook\n",
    "\n",
    "storage_context = StorageContext.from_defaults(\n",
    "    persist_dir=\"../../data/llama_index_indices/handbook/\"\n",
    ")\n",
    "\n",
    "vector_index = load_index_from_storage(\n",
    "    storage_context=storage_context,\n",
    "    settings=settings,\n",
    ")  # load the data index from storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To load in the example Paul Graham data\n",
    "# reader = SimpleDirectoryReader(\"./data/paul_graham/\")\n",
    "# documents = reader.load_data()\n",
    "# vector_index = VectorStoreIndex.from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8581eb5c4f104a14a0f6eb379c716ada",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kgoldmann/Documents/Projects/reginald/.venv/lib/python3.11/site-packages/llama_index/core/evaluation/dataset_generation.py:213: DeprecationWarning: Call to deprecated class DatasetGenerator. (Deprecated in favor of `RagDatasetGenerator` which should be used instead.)\n",
      "  return cls(\n"
     ]
    }
   ],
   "source": [
    "dataset_generator = DatasetGenerator.from_documents(\n",
    "    vector_index.docstore.docs.values(),\n",
    "    num_questions_per_chunk=1,\n",
    "    show_progress=True,\n",
    "    llm=ollama_llm\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_questions = dataset_generator.generate_questions_from_nodes(5)  # generate questions from the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt': 'What is a page in the handbook made of',\n",
       " 'completion': 'A page in the handbook is made of a YAML front matter section followed by the page contents in Markdown. The front matter contains keys such as `title` and `weight`, which define metadata about the page. The content section is formatted in Markdown and can contain built-in or custom shortcodes.'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load in the jsonl file\n",
    "import json\n",
    "import pandas as pd\n",
    "import jsonlines\n",
    "\n",
    "\n",
    "file_path = '/Users/kgoldmann/Documents/Projects/reginald/data/handbook_qa/data/qAndA.json'\n",
    "\n",
    "def load_multiline_jsonl(file_path):\n",
    "    objects = []\n",
    "    buffer = \"\"\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            buffer += line\n",
    "            try:\n",
    "                obj = json.loads(buffer)\n",
    "                objects.append(obj)\n",
    "                buffer = \"\"  # Reset the buffer after a successful load\n",
    "            except json.JSONDecodeError:\n",
    "                # If a JSONDecodeError occurs, it means the current buffer is not a complete JSON object yet\n",
    "                continue\n",
    "    return objects\n",
    "\n",
    "\n",
    "json_objects = load_multiline_jsonl(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_questions = [x['prompt'] for x in json_objects]\n",
    "gpt3_answers = [x['completion'] for x in json_objects]\n",
    "\n",
    "eval_questions = eval_questions[:10]\n",
    "gpt3_answers = gpt3_answers[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer the Questions with Llama 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_gpt4 = RelevancyEvaluator(llm=ollama_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for every value in eval_questions, get the response from the llm\n",
    "all_dfs = []\n",
    "\n",
    "for i in range(len(eval_questions)):\n",
    "    query_engine = vector_index.as_query_engine()\n",
    "    response_vector = query_engine.query(eval_questions[i])\n",
    "    eval_result = evaluator_gpt4.evaluate_response(\n",
    "        query=eval_questions[i], response=response_vector\n",
    "    )\n",
    "\n",
    "    # append to the all_dfs list\n",
    "    all_dfs.append({'eval_result': eval_result,\n",
    "                    'question': eval_questions[i],\n",
    "                    'response': response_vector})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the different elements\n",
    "questions = [x['question'] for x in all_dfs]\n",
    "response = [x['response'] for x in all_dfs]\n",
    "sources = [x['response'].source_nodes for x in all_dfs]\n",
    "#sources = [x[0].node.get_content() for x in sources]\n",
    "\n",
    "# for the each sources, get the content as one string deliminated by ;\n",
    "sources = [\";\".join([x.get_content() for x in y]) for y in sources]\n",
    "\n",
    "match = [x['eval_result'].passing for x in all_dfs] # does the response match the source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the questions\n",
    "combined_df = pd.DataFrame({'questions': questions, 'response': response, 'sources': sources, 'match': match})\n",
    "combined_df.to_csv(\"data/handbook_QandA.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df_out = combined_df.style.set_properties(\n",
    "        **{\n",
    "            \"inline-size\": \"600px\",\n",
    "            \"overflow-wrap\": \"break-word\",\n",
    "        }\n",
    "    )\n",
    "display(combined_df_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ask Reginal the Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 19 key-value pairs and 291 tensors from /Users/kgoldmann/Library/Caches/llama_index/models/llama-2-7b-chat.Q4_K_M.gguf (version GGUF V2)\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = LLaMA v2\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 4096\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 11008\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 32\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000001\n",
      "llama_model_loader: - kv  10:                          general.file_type u32              = 15\n",
      "llama_model_loader: - kv  11:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  12:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  15:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  17:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  18:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q4_K:  193 tensors\n",
      "llama_model_loader: - type q6_K:   33 tensors\n",
      "llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n",
      "llm_load_print_meta: format           = GGUF V2\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32000\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 4096\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 32\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 1\n",
      "llm_load_print_meta: n_embd_k_gqa     = 4096\n",
      "llm_load_print_meta: n_embd_v_gqa     = 4096\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-06\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 11008\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 4096\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: model type       = 7B\n",
      "llm_load_print_meta: model ftype      = Q4_K - Medium\n",
      "llm_load_print_meta: model params     = 6.74 B\n",
      "llm_load_print_meta: model size       = 3.80 GiB (4.84 BPW) \n",
      "llm_load_print_meta: general.name     = LLaMA v2\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 2 '</s>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_tensors: ggml ctx size =    0.15 MiB\n",
      "llm_load_tensors: offloading 0 repeating layers to GPU\n",
      "llm_load_tensors: offloaded 0/33 layers to GPU\n",
      "llm_load_tensors:        CPU buffer size =  3891.24 MiB\n",
      "..................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 4096\n",
      "llama_new_context_with_model: n_batch    = 512\n",
      "llama_new_context_with_model: n_ubatch   = 512\n",
      "llama_new_context_with_model: flash_attn = 0\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:        CPU KV buffer size =  2048.00 MiB\n",
      "llama_new_context_with_model: KV self size  = 2048.00 MiB, K (f16): 1024.00 MiB, V (f16): 1024.00 MiB\n",
      "llama_new_context_with_model:        CPU  output buffer size =     0.12 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =   296.01 MiB\n",
      "llama_new_context_with_model: graph nodes  = 1030\n",
      "llama_new_context_with_model: graph splits = 1\n",
      "AVX = 0 | AVX_VNNI = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | SSSE3 = 0 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \n",
      "Model metadata: {'general.quantization_version': '2', 'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'tokenizer.ggml.bos_token_id': '1', 'tokenizer.ggml.model': 'llama', 'llama.attention.head_count_kv': '32', 'llama.context_length': '4096', 'llama.attention.head_count': '32', 'llama.rope.dimension_count': '128', 'general.file_type': '15', 'llama.feed_forward_length': '11008', 'llama.embedding_length': '4096', 'llama.block_count': '32', 'general.architecture': 'llama', 'llama.attention.layer_norm_rms_epsilon': '0.000001', 'general.name': 'LLaMA v2'}\n",
      "Using fallback chat format: llama-2\n"
     ]
    }
   ],
   "source": [
    "response_model = setup_llm(\n",
    "    model=\"llama-index-llama-cpp\",\n",
    "    model_name=\"../../../llama-2-7b-chat.Q4_K_M.gguf\",\n",
    "    data_dir=\"../../data/\",\n",
    "    which_index=\"handbook\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(question):\n",
    "    resp = response_model.direct_message(message=que, user_id=\"\")\n",
    "    return(resp.message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    6460.86 ms\n",
      "llama_print_timings:      sample time =      27.92 ms /   300 runs   (    0.09 ms per token, 10743.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =   20115.94 ms /  1524 tokens (   13.20 ms per token,    75.76 tokens per second)\n",
      "llama_print_timings:        eval time =   20862.33 ms /   299 runs   (   69.77 ms per token,    14.33 tokens per second)\n",
      "llama_print_timings:       total time =   41499.15 ms /  1823 tokens\n",
      "WARNING:root:Was expecting a backend response with a regular expression but couldn't find a match.\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6460.86 ms\n",
      "llama_print_timings:      sample time =      38.89 ms /   405 runs   (    0.10 ms per token, 10412.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8871.27 ms /   560 tokens (   15.84 ms per token,    63.13 tokens per second)\n",
      "llama_print_timings:        eval time =   28696.71 ms /   404 runs   (   71.03 ms per token,    14.08 tokens per second)\n",
      "llama_print_timings:       total time =   38295.25 ms /   964 tokens\n",
      "WARNING:root:Was expecting a backend response with a regular expression but couldn't find a match.\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6460.86 ms\n",
      "llama_print_timings:      sample time =      47.48 ms /   491 runs   (    0.10 ms per token, 10341.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =   12552.01 ms /   992 tokens (   12.65 ms per token,    79.03 tokens per second)\n",
      "llama_print_timings:        eval time =   34338.38 ms /   490 runs   (   70.08 ms per token,    14.27 tokens per second)\n",
      "llama_print_timings:       total time =   47781.09 ms /  1482 tokens\n",
      "WARNING:root:Was expecting a backend response with a regular expression but couldn't find a match.\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6460.86 ms\n",
      "llama_print_timings:      sample time =      27.05 ms /   288 runs   (    0.09 ms per token, 10648.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =   17690.31 ms /  1360 tokens (   13.01 ms per token,    76.88 tokens per second)\n",
      "llama_print_timings:        eval time =   21291.73 ms /   287 runs   (   74.19 ms per token,    13.48 tokens per second)\n",
      "llama_print_timings:       total time =   39495.99 ms /  1647 tokens\n",
      "WARNING:root:Was expecting a backend response with a regular expression but couldn't find a match.\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6460.86 ms\n",
      "llama_print_timings:      sample time =      48.28 ms /   512 runs   (    0.09 ms per token, 10605.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =   32684.89 ms /  2353 tokens (   13.89 ms per token,    71.99 tokens per second)\n",
      "llama_print_timings:        eval time =   40291.63 ms /   511 runs   (   78.85 ms per token,    12.68 tokens per second)\n",
      "llama_print_timings:       total time =   73935.01 ms /  2864 tokens\n",
      "WARNING:root:Was expecting a backend response with a regular expression but couldn't find a match.\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6460.86 ms\n",
      "llama_print_timings:      sample time =      47.50 ms /   484 runs   (    0.10 ms per token, 10189.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =   33708.04 ms /  2362 tokens (   14.27 ms per token,    70.07 tokens per second)\n",
      "llama_print_timings:        eval time =   42952.07 ms /   483 runs   (   88.93 ms per token,    11.25 tokens per second)\n",
      "llama_print_timings:       total time =   77572.36 ms /  2845 tokens\n",
      "WARNING:root:Was expecting a backend response with a regular expression but couldn't find a match.\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6460.86 ms\n",
      "llama_print_timings:      sample time =      39.30 ms /   433 runs   (    0.09 ms per token, 11018.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =   51270.92 ms /  3617 tokens (   14.17 ms per token,    70.55 tokens per second)\n",
      "llama_print_timings:        eval time =   36633.80 ms /   432 runs   (   84.80 ms per token,    11.79 tokens per second)\n",
      "llama_print_timings:       total time =   88715.20 ms /  4049 tokens\n",
      "WARNING:root:Was expecting a backend response with a regular expression but couldn't find a match.\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6460.86 ms\n",
      "llama_print_timings:      sample time =      25.40 ms /   282 runs   (    0.09 ms per token, 11102.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =   53643.79 ms /  3768 tokens (   14.24 ms per token,    70.24 tokens per second)\n",
      "llama_print_timings:        eval time =   23710.31 ms /   281 runs   (   84.38 ms per token,    11.85 tokens per second)\n",
      "llama_print_timings:       total time =   77863.02 ms /  4049 tokens\n",
      "WARNING:root:Was expecting a backend response with a regular expression but couldn't find a match.\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6460.86 ms\n",
      "llama_print_timings:      sample time =      44.72 ms /   512 runs   (    0.09 ms per token, 11449.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =   35291.82 ms /  2531 tokens (   13.94 ms per token,    71.72 tokens per second)\n",
      "llama_print_timings:        eval time =   41765.07 ms /   511 runs   (   81.73 ms per token,    12.24 tokens per second)\n",
      "llama_print_timings:       total time =   78001.40 ms /  3042 tokens\n",
      "WARNING:root:Was expecting a backend response with a regular expression but couldn't find a match.\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    6460.86 ms\n",
      "llama_print_timings:      sample time =      34.72 ms /   371 runs   (    0.09 ms per token, 10684.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =   48920.56 ms /  3432 tokens (   14.25 ms per token,    70.15 tokens per second)\n",
      "llama_print_timings:        eval time =   31324.74 ms /   370 runs   (   84.66 ms per token,    11.81 tokens per second)\n",
      "llama_print_timings:       total time =   80910.18 ms /  3802 tokens\n",
      "WARNING:root:Was expecting a backend response with a regular expression but couldn't find a match.\n"
     ]
    }
   ],
   "source": [
    "all_questions = eval_questions #combined_df['questions'].tolist()\n",
    "reg_responses = []\n",
    "for que in all_questions:\n",
    "        reg_responses.append(get_response(que))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['  A page in the REG Handbook is made up of several components:\\n1. Front Matter: The front matter is the top section of a content file and contains metadata about the page, such as its title, weight, and other information. It is defined using YAML and is written at the top of each page.\\n2. Content Section: The content section is the main section of the page and contains the actual content of the page. It is written in Markdown format and can include text, images, tables, and other elements.\\n3. Shortcodes: Shortcodes are predefined templates that can be used to include more complex features or content in a page. They can be called using the `{{% shortcode }}` syntax and can be particularly useful for including things like figures, gists, highlights, and references.\\n4. Theme Shortcodes: The theme has its own set of shortcodes that can be used to include additional functionality or content in a page. These shortcodes are typically defined in the theme\\'s README file.\\n5. Repository Shortcodes: Shortcodes can also be included in the handbook\\'s repository. For more information, see the \"Creating Shortcodes\" section of the contributing guide.\\nBy organizing pages in this way, the handbook makes it easy to navigate and find relevant content, and allows for a consistent and well-structured layout across all pages.\\n\\n\\nI read the following documents to compose this answer:\\nhttps://alan-turing-institute.github.io/REG-handbook/docs/contributing/editing_a_page/ (similarity: 0.53)\\n\\nhttps://alan-turing-institute.github.io/REG-handbook/docs/contributing/creating_a_page/ (similarity: 0.51)\\n\\nhttps://alan-turing-institute.github.io/REG-handbook/docs/contributing/getting_started/ (similarity: 0.39)',\n",
       " \"  The purpose of front matter in a book or document is to provide important information about the document, such as its title, author, publisher, date, and other metadata. Front matter typically appears at the beginning of a document and includes the following elements:\\n1. Title page: This page contains the title of the book or document, often followed by the name of the author(s) and the publisher's name.\\n2. Copyright page: This page contains information about the copyright holder, including the year of publication, the name of the publisher, and any applicable copyright symbols or notices.\\n3. Table of contents: A list of the chapters or sections in the document, along with their page numbers.\\n4. Dedication: A section where the author may acknowledge individuals or organizations that have contributed to the book in some way.\\n5. Foreword: An introduction to the book, written by someone other than the author, often to provide context or background information.\\n6. Preface: An introduction to the book, written by the author, to provide an overview of the content and purpose of the document.\\n7. Acknowledgments: A section where the author acknowledges individuals or organizations that have contributed to the book in some way, such as providing research assistance or supporting the publication.\\n8. Maps and illustrations: A list of maps, illustrations, or other graphics included in the book, along with their page numbers.\\n9. Glossary: A list of definitions for technical terms or jargon used in the book.\\n10. Index: A comprehensive list of all the terms and concepts discussed in the book, along with their page numbers.\\nThe front matter provides important information that helps readers navigate the document, find relevant content, and understand its context and purpose. It also provides a professional appearance and helps to establish the credibility of the author and publisher.\\n\\n\\nI read the following documents to compose this answer:\\nhttps://alan-turing-institute.github.io/REG-handbook/docs/contributing/editing_a_page/ (similarity: 0.3)\\n\\nhttps://alan-turing-institute.github.io/REG-handbook/docs/contributing/creating_a_page/ (similarity: 0.13)\\n\\nhttps://alan-turing-institute.github.io/REG-handbook/docs/contributing/advanced/ (similarity: 0.13)\",\n",
       " \"  The keys or elements most commonly used in front matter vary depending on the type of document, but here are some common ones:\\n1. Title: The title of the document, which is usually placed on the title page.\\n2. Author: The name(s) of the author(s) of the document.\\n3. Publisher: The name of the publisher or organization responsible for publishing the document.\\n4. Date: The date of publication or creation of the document.\\n5. Edition: For documents that have multiple editions, the edition number or version number is often included in the front matter.\\n6. Series: If the document is part of a series, the name of the series and the volume number are often included in the front matter.\\n7. Description: A brief summary or description of the document's content.\\n8. Keywords: A list of keywords or subject headings that can be used to classify the document.\\n9. Classifications: The document's classification or categorization, such as Dewey Decimal System or Library of Congress Subject Headings.\\n10. Table of Contents: An outline of the document's structure, including the page numbers for each section.\\n11. Dedication: A message acknowledging individuals or organizations that have contributed to the document.\\n12. Foreword: An introduction to the document written by someone other than the author, often to provide context or background information.\\n13. Preface: An introduction to the document written by the author, to provide an overview of the content and purpose of the document.\\n14. Acknowledgments: A section acknowledging individuals or organizations that have contributed to the document in some way, such as providing research assistance or supporting the publication.\\n15. Maps and illustrations: A list of maps, illustrations, or other graphics included in the document, along with their page numbers.\\n16. Glossary: A list of definitions for technical terms or jargon used in the document.\\n17. Index: A comprehensive list of all the terms and concepts discussed in the document, along with their page numbers.\\nThese are some of the most common keys used in front matter, but depending on the type of document, there may be other elements included as well.\\n\\n\\nI read the following documents to compose this answer:\\nhttps://alan-turing-institute.github.io/REG-handbook/docs/contributing/editing_a_page/ (similarity: 0.24)\\n\\nhttps://alan-turing-institute.github.io/REG-handbook/docs/technical_practices/ (similarity: 0.19)\\n\\nhttps://alan-turing-institute.github.io/REG-handbook/docs/contributing/ (similarity: 0.15)\",\n",
       " '  In the context of front matter in a book or document, the \"weight\" key is used to indicate the importance or priority of a page or section within the document. The weight is usually assigned a number value, with higher numbers indicating more important pages.\\nThe weight key is often used in conjunction with the title key to create a hierarchical structure for the document\\'s content. For example, the title page may have a weight of 1, while the table of contents may have a weight of 2, and the chapters may have weights based on their length or importance.\\nThe weight key can be useful in several ways:\\n1. Navigation: A higher-weight page is more likely to be displayed or accessed first when users navigate through the document.\\n2. Citation: The weight of a page can influence how often it is cited or referenced by other pages in the document.\\n3. Organization: By assigning weights to different sections, the author can create a clear hierarchy of content and guide readers through the document more easily.\\n4. Search engine optimization (SEO): In some cases, search engines may use weight to determine the importance of a page for SEO purposes.\\nIt\\'s worth noting that the weight key is not a standard element in all documents, and its usage may vary depending on the type of document and the purpose of the front matter.\\n\\n\\nI read the following documents to compose this answer:\\nhttps://alan-turing-institute.github.io/REG-handbook/docs/contributing/editing_a_page/ (similarity: 0.22)\\n\\nhttps://alan-turing-institute.github.io/REG-handbook/docs/onboarding/new_joiners/ (similarity: 0.11)\\n\\nhttps://alan-turing-institute.github.io/REG-handbook/docs/how_we_work/ (similarity: 0.11)',\n",
       " \"  The Handbook theme for Hugo provides several predefined front matter keys that you can use in your documentation. Here are some of the most commonly used ones:\\n1. title: The title of your document, which will appear on the title page.\\n2. author: The name of the author or authors of the document.\\n3. date: The date of publication or creation of the document.\\n4. description: A brief summary or description of the document's content.\\n5. keywords: A list of keywords or subject headings that can be used to classify the document.\\n6. tableofcontents: An outline of the document's structure, including the page numbers for each section.\\n7. dedication: A message acknowledging individuals or organizations that have contributed to the document.\\n8. foreword: An introduction to the document written by someone other than the author, often to provide context or background information.\\n9. preface: An introduction to the document written by the author, to provide an overview of the content and purpose of the document.\\n10. acknowledgments: A section acknowledging individuals or organizations that have contributed to the document in some way, such as providing research assistance or supporting the publication.\\nYou can find these predefined front matter keys in the `config.toml` file of the Handbook theme. Here's where you can find them:\\n1. `title`: `config.toml` file, under the `theme` section, in the `title` key.\\n2. `author`: `config.toml` file, under the `theme` section, in the `author` key.\\n3. `date`: `config.toml` file, under the `theme` section, in the `date` key.\\n4. `description`: `config.toml` file, under the `theme` section, in the `description` key.\\n5. `keywords`: `config.toml` file, under the `theme` section, in the `keywords` key.\\n6. `tableofcontents`: `config.toml` file, under the `theme` section, in the `tableofcontents` key.\\n7. `dedication`: `config.toml` file, under the `theme` section, in the `dedication` key.\\n8. `foreword`: `config.toml`\\n\\n\\nI read the following documents to compose this answer:\\nhttps://alan-turing-institute.github.io/REG-handbook/docs/contributing/editing_a_page/ (similarity: 0.51)\\n\\nhttps://alan-turing-institute.github.io/REG-handbook/docs/contributing/creating_a_page/ (similarity: 0.37)\\n\\nhttps://alan-turing-institute.github.io/REG-handbook/docs/contributing/getting_started/ (similarity: 0.33)\",\n",
       " '  In the Handbook theme for Hugo, the \"content\" section is where you can add the main content of your page. This section is typically placed between the front matter and the back matter, and it contains the meat of your document\\'s content.\\nThe content section is defined in the `config.toml` file of the Handbook theme, and it can contain any valid Hugo markup, such as:\\n1. Markdown: Useful for creating paragraphs, lists, images, and other types of content.\\n2. Code blocks: Useful for displaying code snippets or examples.\\n3. Tables: Useful for presenting data in a tabular format.\\n4. Images: Useful for adding visual content to your document.\\n5. Footnotes: Useful for including additional information or citations at the bottom of a page.\\n6. Definition lists: Useful for defining terms or concepts.\\n7. Quotes: Useful for highlighting important quotes or passages.\\n8. Abbreviations: Useful for defining abbreviations or acronyms used in your document.\\n9. Glossary: Useful for creating a comprehensive glossary of terms used in your document.\\n10. References: Useful for listing sources or references cited in your document.\\nThe content section can be further divided into subsections using the `section` element, which allows you to create nested sections within your document. For example:\\n```\\n# Introduction\\n## Subsection 1\\nSome text here...\\n\\n## Subsection 2\\nEven more text here...\\n```\\nThe Handbook theme also provides some built-in layout options for the content section, such as the ability to create a table of contents, set the page size and margins, and define custom page headers and footers. You can find these options in the `config.toml` file under the `content` section.\\nIn summary, the content section of a page in the Handbook theme is where you can add the main content of your document, using any valid Hugo markup. The section can be further divided into subsections using the `section` element, and it can also take advantage of some built-in layout options to customize the look and feel of your document.\\n\\n\\nI read the following documents to compose this answer:\\nhttps://alan-turing-institute.github.io/REG-handbook/docs/contributing/editing_a_page/ (similarity: 0.57)\\n\\nhttps://alan-turing-institute.github.io/REG-handbook/docs/contributing/creating_a_page/ (similarity: 0.54)\\n\\nhttps://alan-turing-institute.github.io/REG-handbook/docs/contributing/discussions_and_issues/ (similarity: 0.41)',\n",
       " '  Markdown is a lightweight markup language that allows you to format text and create documents with a consistent look and feel. It was created by John Gruber in 2004 and has since become a popular choice for writing and formatting content on the web.\\nMarkdown is based on plain text formatting, which means that it uses simple characters and symbols to indicate different types of formatting, such as headings, bold text, italic text, lists, and links. This makes it easy to read and write Markdown files, as well as to convert them to other formats, such as HTML or PDF.\\nSome of the key features of Markdown include:\\n1. Headers: Markdown allows you to create headings with different levels of hierarchy using #, ##, and ### symbols.\\n2. Bold and italic text: You can make text bold or italic using *asterisks* or **double asterisks**, respectively.\\n3. Lists: Markdown supports two types of lists: ordered (numbered) lists and unordered (bulleted) lists. To create an ordered list, use numbers enclosed in square brackets, while to create an unordered list, use hyphens or stars enclosed in square brackets.\\n4. Links: You can create links to other web pages or emails using [text](url).\\n5. Images: Markdown allows you to add images to your documents using ![image alt text](url).\\n6. Code blocks: Markdown provides a simple way to format code using triple backticks ``` and four spaces before each line of code.\\n7. Tables: Markdown supports basic tables using | characters to separate columns and rows.\\n8. Definition lists: Markdown allows you to define terms and their descriptions using definitions lists, which are denoted by a double hyphen (-) at the beginning of a line.\\n9. Footnotes: Markdown provides a way to create footnotes using [^text].\\nMarkdown is often used for writing documentation, readme files, and other\\n\\n\\nI read the following documents to compose this answer:\\nhttps://alan-turing-institute.github.io/REG-handbook/docs/contributing/style_guide/ (similarity: 0.31)\\n\\nhttps://alan-turing-institute.github.io/REG-handbook/docs/contributing/editing_a_page/ (similarity: 0.3)\\n\\nhttps://alan-turing-institute.github.io/REG-handbook/docs/contributing/advanced/ (similarity: 0.28)',\n",
       " '  In the Handbook theme for Hugo, shortcodes are predefined code snippets that you can use to insert common elements or functionality into your documents. Shortcodes are defined in the `shortcodes` directory of the Handbook theme, and they are typically used in conjunction with Markdown syntax to create custom layouts and designs.\\nHere are some examples of shortcodes that are included in the Handbook theme:\\n1. `section`: Creates a new section with a specified title.\\nExample: `[section title=\"My Section\"]This is my section![/section]`\\n2. `subsection`: Creates a new subsection within a section.\\nExample: `[subsection title=\"My Subsection\"]This is my subsection![/subsection]`\\n3. `paragraph`: Inserts a new paragraph of text.\\nExample: `[paragraph]`This is a new paragraph![/paragraph]`\\n4. `quote`: Inserts a quote with a specified author and text.\\nExample: `[quote author=\"John Doe\"]\"This is a quote.\"[/quote]`\\n5. `image`: Inserts an image with a specified URL.\\nExample: `[image url=\"https://example.com/image.jpg\"]This is an image![/image]`\\n6. `code`: Inserts a code block with a specified language and\\n\\n\\nI read the following documents to compose this answer:\\nhttps://alan-turing-institute.github.io/REG-handbook/docs/contributing/advanced/ (similarity: 0.45)\\n\\nhttps://alan-turing-institute.github.io/REG-handbook/docs/contributing/editing_a_page/ (similarity: 0.34)\\n\\nhttps://alan-turing-institute.github.io/REG-handbook/docs/contributing/ (similarity: 0.32)',\n",
       " \"  Shortcodes and raw HTML are two different ways to include content in a Hugo website, each with their own advantages and use cases.\\nRaw HTML:\\n* Includes HTML code directly in your Markdown files, without any processing or transformation by Hugo.\\nAdvantages:\\n\\n* Allows for precise control over the structure and layout of your content, as you can write raw HTML code directly in your Markdown files.\\n* Can be useful for creating complex layouts or designs that don't fit into the default Hugo template.\\nDisadvantages:\\n\\n* Requires manual editing of your Markdown files, which can be time-consuming and error-prone.\\n* May not be compatible with all Hugo features, such as syntax highlighting or responsive design.\\n\\nShortcodes:\\n* Are predefined code snippets that you can use in your Markdown files to insert content, such as images, quotes, or code blocks.\\nAdvantages:\\n\\n* Simplifies the process of including content in your Markdown files, as you don't need to write raw HTML code.\\n* Can be easily integrated with Hugo's built-in features, such as syntax highlighting or responsive design.\\n* Provides a consistent and predictable way of inserting content throughout your website.\\nDisadvantages:\\n\\n* Limited flexibility compared to writing raw HTML code directly in your Markdown files.\\n* May not be suitable for creating complex layouts or designs that require precise control over the structure and layout of your content.\\nWhen to use raw HTML:\\n\\n\\n* When you need to include content that requires precise control over the structure and layout of your content, such as complex layouts or designs.\\n* When you want to integrate custom code or functionality into your website that isn't compatible with Hugo's built-in features.\\n\\nWhen to use shortcodes:\\n\\n\\n* When you want to simplify the process of including content in your Markdown files and provide a consistent way of inserting content throughout your website.\\n* When you want to leverage Hugo's built-in features, such as syntax highlighting or responsive design, to enhance the look and feel of your content.\\nIn summary, raw HTML provides more flexibility and control over the structure and layout of your content, while shortcodes simplify the process of including content in your Markdown files and provide a consistent way of inserting content throughout\\n\\n\\nI read the following documents to compose this answer:\\nhttps://alan-turing-institute.github.io/REG-handbook/docs/contributing/advanced/ (similarity: 0.47)\\n\\nhttps://alan-turing-institute.github.io/REG-handbook/docs/contributing/editing_a_page/ (similarity: 0.26)\\n\\nhttps://alan-turing-institute.github.io/REG-handbook/docs/contributing/creating_a_page/ (similarity: 0.23)\",\n",
       " '  Hugo comes with several built-in shortcodes that you can use to insert common elements or functionality into your content. Here are some of the most commonly used shortcodes in Hugo:\\n1. `section`: Creates a new section with a specified title.\\nExample: `[section title=\"My Section\"]This is my section![/section]`\\n2. `subsection`: Creates a new subsection within a section.\\nExample: `[subsection title=\"My Subsection\"]This is my subsection![/subsection]`\\n3. `paragraph`: Inserts a new paragraph of text.\\nExample: `[paragraph]`This is a new paragraph![/paragraph]`\\n4. `quote`: Inserts a quote with a specified author and text.\\nExample: `[quote author=\"John Doe\"]\"This is a quote.\"[/quote]`\\n5. `image`: Inserts an image with a specified URL.\\nExample: `[image url=\"https://example.com/image.jpg\"]This is an image![/image]`\\n6. `code`: Inserts a code block with a specified language and text.\\nExample: `[code lang=\"python\"]print(\"Hello, world!\")[/code]`\\n7. `link`: Creates a link to another page or URL.\\nExample: `[link url=\"https://example.com\"]Visit our website![/link]`\\n8. `footnotes`: Inserts footnotes with a specified text and number.\\nExample: `[footnotes text=\"This is a footnote.\" number=\"1\"]This is the content of the footnote.[/footnotes]`\\n9. `definition`: Creates a definition list with a specified term and description.\\nExample: `[definition term=\"Python\"]Python\\n\\n\\nI read the following documents to compose this answer:\\nhttps://alan-turing-institute.github.io/REG-handbook/docs/contributing/advanced/ (similarity: 0.6)\\n\\nhttps://alan-turing-institute.github.io/REG-handbook/docs/contributing/ (similarity: 0.44)\\n\\nhttps://alan-turing-institute.github.io/REG-handbook/docs/contributing/editing_a_page/ (similarity: 0.44)']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.evaluation import CorrectnessEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluator_gpt4 = RelevancyEvaluator(llm=ollama_llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correctness Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = CorrectnessEvaluator(llm=ollama_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What is a page in the handbook made of',\n",
       " 'What is the purpose of front matter',\n",
       " 'What are the keys most commonly used in front matter',\n",
       " 'What does the weight key do',\n",
       " 'Where can you find the predefined front matter keys for the handbook theme',\n",
       " 'What is the content section of a page in the handbook',\n",
       " 'What is Markdown',\n",
       " 'What are shortcodes in the handbook',\n",
       " 'What is the difference between using a shortcode and raw HTML in a content file',\n",
       " 'What are some of the built-in shortcodes in Hugo']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "outputs = []\n",
    "\n",
    "for i in range(len(all_questions)):\n",
    "    print(i)\n",
    "    query = all_questions[i]\n",
    "\n",
    "    reference = gpt3_answers[i]\n",
    "\n",
    "    response = reg_responses[i]\n",
    "\n",
    "    result = evaluator.evaluate(\n",
    "        query=query,\n",
    "        response=response,\n",
    "        contexts=[reference],\n",
    "    )\n",
    "\n",
    "    outputs.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(reg_responses), len(all_questions), len(gpt3_answers), len(outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_df= pd.DataFrame({\n",
    "    'question': all_questions,\n",
    "    'reg_response': reg_responses,\n",
    "    'gpt_response':gpt3_answers,\n",
    "    'correct': [x.passing for x in outputs]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>reg_response</th>\n",
       "      <th>gpt_response</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is a page in the handbook made of</td>\n",
       "      <td>A page in the REG Handbook is made up of sev...</td>\n",
       "      <td>A page in the handbook is made of a YAML front...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the purpose of front matter</td>\n",
       "      <td>The purpose of front matter in a book or doc...</td>\n",
       "      <td>The purpose of front matter in a Markdown file...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What are the keys most commonly used in front ...</td>\n",
       "      <td>The keys or elements most commonly used in f...</td>\n",
       "      <td>The most commonly used keys in front matter ar...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What does the weight key do</td>\n",
       "      <td>In the context of front matter in a book or ...</td>\n",
       "      <td>The weight key in the front matter of a page d...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Where can you find the predefined front matter...</td>\n",
       "      <td>The Handbook theme for Hugo provides several...</td>\n",
       "      <td>The predefined front matter keys for the handb...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What is the content section of a page in the h...</td>\n",
       "      <td>In the Handbook theme for Hugo, the \"content...</td>\n",
       "      <td>The content section of a page in the handbook ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What is Markdown</td>\n",
       "      <td>Markdown is a lightweight markup language th...</td>\n",
       "      <td>Markdown is a formatting language used to crea...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>What are shortcodes in the handbook</td>\n",
       "      <td>In the Handbook theme for Hugo, shortcodes a...</td>\n",
       "      <td>Shortcodes are templates that can be parameter...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>What is the difference between using a shortco...</td>\n",
       "      <td>Shortcodes and raw HTML are two different wa...</td>\n",
       "      <td>Using a shortcode is preferable to including r...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>What are some of the built-in shortcodes in Hugo</td>\n",
       "      <td>Hugo comes with several built-in shortcodes ...</td>\n",
       "      <td>Hugo has a set of built-in shortcodes includin...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0             What is a page in the handbook made of   \n",
       "1                What is the purpose of front matter   \n",
       "2  What are the keys most commonly used in front ...   \n",
       "3                        What does the weight key do   \n",
       "4  Where can you find the predefined front matter...   \n",
       "5  What is the content section of a page in the h...   \n",
       "6                                   What is Markdown   \n",
       "7                What are shortcodes in the handbook   \n",
       "8  What is the difference between using a shortco...   \n",
       "9   What are some of the built-in shortcodes in Hugo   \n",
       "\n",
       "                                        reg_response  \\\n",
       "0    A page in the REG Handbook is made up of sev...   \n",
       "1    The purpose of front matter in a book or doc...   \n",
       "2    The keys or elements most commonly used in f...   \n",
       "3    In the context of front matter in a book or ...   \n",
       "4    The Handbook theme for Hugo provides several...   \n",
       "5    In the Handbook theme for Hugo, the \"content...   \n",
       "6    Markdown is a lightweight markup language th...   \n",
       "7    In the Handbook theme for Hugo, shortcodes a...   \n",
       "8    Shortcodes and raw HTML are two different wa...   \n",
       "9    Hugo comes with several built-in shortcodes ...   \n",
       "\n",
       "                                        gpt_response correct  \n",
       "0  A page in the handbook is made of a YAML front...    True  \n",
       "1  The purpose of front matter in a Markdown file...    True  \n",
       "2  The most commonly used keys in front matter ar...    None  \n",
       "3  The weight key in the front matter of a page d...    True  \n",
       "4  The predefined front matter keys for the handb...    True  \n",
       "5  The content section of a page in the handbook ...    True  \n",
       "6  Markdown is a formatting language used to crea...    None  \n",
       "7  Shortcodes are templates that can be parameter...    True  \n",
       "8  Using a shortcode is preferable to including r...    True  \n",
       "9  Hugo has a set of built-in shortcodes includin...    True  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_df.to_csv(\"data/handbook_QandA_correctness.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama-index",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
