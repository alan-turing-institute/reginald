{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.evaluation import DatasetGenerator, RelevancyEvaluator\n",
    "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex, Response\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.llms.azure_openai import AzureOpenAI\n",
    "from llama_index.embeddings.azure_openai import AzureOpenAIEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.azure_openai import AzureOpenAI\n",
    "\n",
    "from reginald.models.models.llama_index import DataIndexCreator\n",
    "\n",
    "import os\n",
    "from reginald.utils import get_env_var\n",
    "\n",
    "from llama_index.readers.github import (\n",
    "    GithubClient,\n",
    "    GitHubIssuesClient,\n",
    "    GitHubRepositoryIssuesReader,\n",
    "    GithubRepositoryReader,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up Azure GPT4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the LLM\n",
    "openai_azure_api_key = os.environ[\"OPENAI_AZURE_API_KEY\"]\n",
    "azure_endpoint = \"https://reginald-uk-south.openai.azure.com/\"\n",
    "api_version = \"2024-02-01\"\n",
    "\n",
    "azure_gpt4 = AzureOpenAI(\n",
    "    model=\"gpt-4\",\n",
    "    deployment_name=\"reginald-gpt4\",\n",
    "    api_key=openai_azure_api_key,\n",
    "    azure_endpoint=azure_endpoint,\n",
    "    api_version=api_version,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup settings for vectorisation later\n",
    "from reginald.models.models.llama_index import setup_settings\n",
    "from reginald.models.setup_llm import DEFAULT_ARGS\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "from reginald.models.models.llama_index import (\n",
    "    setup_settings,\n",
    "    LlamaIndexLlamaCPP,\n",
    "    set_global_tokenizer,\n",
    "    compute_default_chunk_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up settings\n",
    "chunk_size = compute_default_chunk_size(\n",
    "    max_input_size=4096, k=3\n",
    ")  # calculate chunk size\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"meta-llama/Llama-2-7b-chat-hf\"\n",
    ").encode\n",
    "\n",
    "set_global_tokenizer(tokenizer)\n",
    "\n",
    "settings = setup_settings(\n",
    "    llm                 = azure_gpt4,\n",
    "    max_input_size      = DEFAULT_ARGS[\"max_input_size\"],\n",
    "    num_output          = DEFAULT_ARGS[\"num_output\"],\n",
    "    chunk_size          = chunk_size,\n",
    "    chunk_overlap_ratio = DEFAULT_ARGS[\"chunk_overlap_ratio\"],\n",
    "    k                   = DEFAULT_ARGS[\"k\"],\n",
    "    tokenizer           = tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the pre-generated questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gh_token = get_env_var(\"GITHUB_TOKEN\")\n",
    "\n",
    "owner = \"alan-turing-institute\"\n",
    "repo = \"REG-handbook\"\n",
    "\n",
    "handbook_loader = GithubRepositoryReader(\n",
    "    GithubClient(gh_token, fail_on_http_error=False),\n",
    "    owner=owner,\n",
    "    repo=repo,\n",
    "    verbose=False,\n",
    "    concurrent_requests=1,\n",
    "    timeout=60,\n",
    "    retries=3,\n",
    "    filter_file_extensions=(\n",
    "        [\".md\"],\n",
    "        GithubRepositoryReader.FilterType.INCLUDE,\n",
    "    ),\n",
    "    filter_directories=(\n",
    "        [\"content\"],\n",
    "        GithubRepositoryReader.FilterType.INCLUDE,\n",
    "    ),\n",
    ")\n",
    "\n",
    "handbook_data = handbook_loader.load_data(branch=\"main\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator = DatasetGenerator.from_documents(handbook_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "save_name = \"handbook_eval_questions.json\"\n",
    "\n",
    "# Load from the JSON file\n",
    "with open(os.path.join('../../data/evaluations',save_name), 'r') as file:\n",
    "    loaded_eval_questions = json.load(file)\n",
    "    \n",
    "loaded_eval_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create vector index\n",
    "vector_index = VectorStoreIndex.from_documents(handbook_data, show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_eval_questions[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query_engine    = vector_index.as_query_engine()\n",
    "# response_vector = query_engine.query(loaded_eval_questions[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming vector_index and eval_questions are already defined\n",
    "\n",
    "# query_engine = vector_index.as_query_engine()\n",
    "\n",
    "# # Create a list or dictionary to store the responses\n",
    "# response_vectors = []\n",
    "\n",
    "# # Iterate over each question in eval_questions\n",
    "# for question in loaded_eval_questions:\n",
    "#     response = query_engine.query(question)\n",
    "#     response_vectors.append(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get answers in batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "def evaluate_query_engine(query_engine, questions):\n",
    "    c = [query_engine.aquery(q) for q in questions]\n",
    "    results = asyncio.run(asyncio.gather(*c))\n",
    "    print(\"finished query\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_query_engine = vector_index.as_query_engine()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "results = evaluate_query_engine(vector_query_engine, loaded_eval_questions[:101])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = []\n",
    "\n",
    "# Define the batch size\n",
    "batch_size = 25\n",
    "\n",
    "# Get the total number of questions\n",
    "total_questions = len(loaded_eval_questions)\n",
    "\n",
    "# Loop over the list in increments of the batch size\n",
    "for i in range(0, total_questions, batch_size):\n",
    "    \n",
    "    # Slice the list to get the current batch\n",
    "    batch = loaded_eval_questions[i:i + batch_size]\n",
    "    \n",
    "    # Evaluate the current batch\n",
    "    results = evaluate_query_engine(vector_query_engine, batch)\n",
    "    \n",
    "    # Optionally, print or store the results\n",
    "    print(f\"Results for batch {i // batch_size + 1} done.\")\n",
    "    \n",
    "    all_results.extend(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the results\n",
    "import pickle\n",
    "\n",
    "# Save the data to a file\n",
    "with open('../../data/evaluations/handbook_eval_answers.pkl', 'wb') as file:\n",
    "    pickle.dump(all_results, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from the file\n",
    "with open('../../data/evaluations/handbook_eval_answers.pkl', 'rb') as file:\n",
    "    loaded_data = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'response': 'The Research Engineering Group is a component of the Alan Turing Institute.',\n",
       " 'source_nodes': [NodeWithScore(node=TextNode(id_='ccaddcc2-7524-4a0b-adf1-922d94187ffa', embedding=None, metadata={'file_path': 'content/docs/join_us/recruitment_FAQs.md', 'file_name': 'recruitment_FAQs.md', 'url': 'https://github.com/alan-turing-institute/REG-handbook/blob/main/content/docs/join_us/recruitment_FAQs.md'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='334a4c021df569ebc7001eeac252ffa542373d53', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'file_path': 'content/docs/join_us/recruitment_FAQs.md', 'file_name': 'recruitment_FAQs.md', 'url': 'https://github.com/alan-turing-institute/REG-handbook/blob/main/content/docs/join_us/recruitment_FAQs.md'}, hash='76b4a5af0f7b39e5ab11bf6cf1be1966d7c3d7a323e60a4951bb4ccd5ef0d900'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='625fcd0a-67d1-4526-82ef-3cceea9f54ac', node_type=<ObjectType.TEXT: '1'>, metadata={'file_path': 'content/docs/join_us/recruitment_FAQs.md', 'file_name': 'recruitment_FAQs.md', 'url': 'https://github.com/alan-turing-institute/REG-handbook/blob/main/content/docs/join_us/recruitment_FAQs.md'}, hash='28dee99fd3879606acf5b6bb6da0dea0ff1fd27d7710950836cc4de18426a9b0'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='f2b55831-a132-48ee-88ac-52a98b3ac766', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5e7a328a3014abcceb84548a8a7e2db8ca39e5bfed81051111d502896fa690aa')}, text='Becoming a member of REG will also bring the following benefits:\\n\\n- Flexible working: we are currently trialling being a “remote-first” group for the entire decision-making process, but as the office is now fully re-opened members are free to choose how often they come into the office.\\n\\n- The opportunity to work and collaborate on cutting-edge data science projects with high-profile institutions, but with the benefits of working in a full-time position (better than a post-doc, better than many data science roles in industry).\\n\\n- Strong input into which projects you work on.\\n  We value providing the experience of learning something new in a collaborative setting, and prioritise staffing people onto projects they would like to work on rather than maximising the fit to people\\'s prior experience.\\n  Our group is made up of people with a wide range of skills and experiences and we generally find we can put together project teams with a suitable mix of skills from those who are enthusiastic about each project.\\n\\n- Formal support for professional development via learning and development plans each team member develops with their line manager during the probation process, annual objective setting and regular 1-2-1s.\\n  These learning plans feed into the projects people are allocated to and the roles and responsibilities they undertake within these.\\n\\n- Support to team members with their development outside of projects, providing 20% time that is split evenly between self-directed development and getting involved in one of the group\\'s or institute\\'s service areas.\\n  We support team members to attend conferences, workshops and courses, and there are many seminar series and interest groups at the Turing that team members are encouraged to get involved with, including the team’s own weekly [tech talks]({{< relref \"docs/regular_events/lunchtime_tech_talks.md\" >}}).\\n  We also support team members making contributions to the wider ecosystem as part of their 20% time.\\n  Examples include contributing to external [Open Source Hacksessions]({{< relref \"docs/regular_events/open_source_hacksessions.md\" >}}) and contributing to community groups like the [Society for Research Software Engineering]({{< relref \"docs/onboarding/society_of_research_software_engineering.md\" >}}).\\n\\n- The opportunity to get involved in non-project work through one of the team\\'s service areas, some of which support the running of the team and some of which support the wider research community at the institute (for instance Recruitment, Planning and finance, Training, EDI, Communications, Research computing support, Research programme liaison).\\n  Some service areas require significant support and will have core team members who have chosen these service areas instead of a full project workload, but all team members have a 10% allocation to volunteer for a service area of their choice.\\n\\n- The opportunity to contribute to how the group works and grows.\\n  We run the team in an open, consultative and collaborative manner and almost all of our decision making on how we organise ourselves and develop the team is done in the open on our group GitHub with the opportunity for anyone in the team to contribute.\\n\\n- [Other benefits](https://www.turing.ac.uk/work-turing/why-work-turing/employee-benefits) include private healthcare and a 13% contribution to a defined contribution pension scheme (3% from the employee, 10% from the Turing).\\n\\n## My question is not answered here\\n\\nPlease contact the REG recruitment team ([reg-recruitment-info@turing.ac.uk](mailto:reg-recruitment-info@turing.ac.uk)) with any additional questions you may have.\\nWe also run monthly drop-in sessions where you can meet some of the current team and ask them questions face to face.\\nThese sessions will be hosted by team members who won\\'t be involved in that month\\'s interview process, and questions you ask at these sessions will have no influence on how your application is treated.', start_char_idx=19196, end_char_idx=23152, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.5026923663716305),\n",
       "  NodeWithScore(node=TextNode(id_='e81c6cb0-ec58-44d5-90a5-32bbb87c8c8f', embedding=None, metadata={'file_path': 'content/docs/onboarding/society_of_research_software_engineering.md', 'file_name': 'society_of_research_software_engineering.md', 'url': 'https://github.com/alan-turing-institute/REG-handbook/blob/main/content/docs/onboarding/society_of_research_software_engineering.md'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='86410ea05e1cb71a248b3b7c33a57ed0fdb1b6a6', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'file_path': 'content/docs/onboarding/society_of_research_software_engineering.md', 'file_name': 'society_of_research_software_engineering.md', 'url': 'https://github.com/alan-turing-institute/REG-handbook/blob/main/content/docs/onboarding/society_of_research_software_engineering.md'}, hash='4676d4342348d41fa33343a45a9009cd0fc1bd9d77deb1bb866a5dd8febcd842')}, text='---\\n# Page title as it appears in the navigation menu\\ntitle: \"SocRSE\"\\n# Adjust weight to reorder menu items (lower numbers appear first)\\nweight: 1\\n# Uncomment to hide nested pages in a collapsed menu\\n# bookCollapseSection = true\\n# Uncomment to hide this page from the navigation menu\\n# bookHidden = false\\n# Uncomment to exclude this page from the search\\n# bookSearchExclude = true\\n---\\n\\n# Society of Research Software Engineering\\n\\nThe [Society of Research Software Engineering](https://society-rse.org/) (SocRSE) is a charitable incorporated organisation\\nwith the mission to establish a research environment that recognises the vital role of software in research.\\n\\nREG supports and encourages its members to join the SocRSE, so it\\'s worth reviewing the society\\'s website and deciding whether to join during your onboarding period.\\n\\n## Benefits of SocRSE\\n\\nThere are many benefits to joining the SocRSE. By joining the Society you will:\\n\\n- Contribute to [the Society\\'s work](https://society-rse.org/community/) supporting the research software engineering community\\n- Gain access to the Society\\'s [Events & Initiatives fund](https://society-rse.org/policy-for-socrse-events-and-initiatives-grant/)\\n- Get discounted access to the Society\\'s annual conference\\n- Be eligible to vote and stand for election at the Society\\'s annual AGM\\n- Have your say in one of the Society\\'s [special interest, regional or working groups](https://society-rse.org/community/get-involved/)\\n- Be able to apply for the Society’s [mentorship scheme](https://society-rse.org/get-involved/mentoring-scheme/)\\n- Gain access to discounts from the Society\\'s corporate sponsors\\n\\n## Communication Channels\\n\\nThe Society has a website, Slack and email list.\\nTheir [Slack workspace](https://ukrse.slack.com/join/signup) contains plenty of details about relevant events.\\n\\n## Claiming Back Subscriptions\\n\\nSocRSE membership is considered a professional subscription, which you are entitled to claim back as a REG member.\\n\\nYou should claim it back quickly after payment.\\nUse Certify to claim it back following [these instructions](https://github.com/alan-turing-institute/research-engineering-group/wiki/Reclaiming-out-of-pocket-expenses#allocating-your-expenses-to-the-right-budget).\\nNote that this expense is not directly related to a project.', start_char_idx=0, end_char_idx=2300, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.437602439266918)],\n",
       " 'metadata': {'ccaddcc2-7524-4a0b-adf1-922d94187ffa': {'file_path': 'content/docs/join_us/recruitment_FAQs.md',\n",
       "   'file_name': 'recruitment_FAQs.md',\n",
       "   'url': 'https://github.com/alan-turing-institute/REG-handbook/blob/main/content/docs/join_us/recruitment_FAQs.md'},\n",
       "  'e81c6cb0-ec58-44d5-90a5-32bbb87c8c8f': {'file_path': 'content/docs/onboarding/society_of_research_software_engineering.md',\n",
       "   'file_name': 'society_of_research_software_engineering.md',\n",
       "   'url': 'https://github.com/alan-turing-institute/REG-handbook/blob/main/content/docs/onboarding/society_of_research_software_engineering.md'}},\n",
       " '__pydantic_initialised__': True}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(loaded_data[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reginald",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
