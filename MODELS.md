We currently have the following models available:

- `hello`: a simple model which responds to a message with a greeting and an emoji
- `llama-index-llama-cpp`: a model which uses the [`llama-index`](https://github.com/jerryjliu/llama_index) library to query a data index and then uses a quantised LLM (implemented using [`llama-python-cpp`](https://github.com/abetlen/llama-cpp-python)) to generate a response
- `llama-index-hf`: a model which uses the [`llama-index`](https://github.com/jerryjliu/llama_index) library to query a data index and then uses an LLM from [Huggingface](https://huggingface.co/models) to generate a response
- `llama-index-gpt-azure`: a model which uses the [`llama-index`](https://github.com/jerryjliu/llama_index) library to query a data index and then uses the Azure OpenAI API to query a LLM to generate a response
- `llama-index-gpt-openai`: a model which uses the [`llama-index`](https://github.com/jerryjliu/llama_index) library to query a data index and then uses the OpenAI API to query a LLM to generate a response
- `chat-completion-azure`: a chat completion model which uses the Azure OpenAI API to query a LLM to generate a response (does not use `llama-index`)
- `chat-completion-openai`: a chat completion model which uses the OpenAI API to query a LLM to generate a response (does not use `llama-index`)

## `llama-index` Models



## `chat-completion` Models
