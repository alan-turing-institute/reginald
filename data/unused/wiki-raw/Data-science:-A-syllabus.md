A page to capture ideas for a “data science” syllabus, suitable for a course or a reference, that could be given to new joiners in REG. Very much a work in progress.


# Mathematical background
- Sets (see, eg, [The Open Logic Project](https://builds.openlogicproject.org/))
- Numbers
- Vectors
- Linear algebra
- Probability, measure, and integration
- Calculus
- Information theory
- Logic
- Graph theory

# Data
## Theory
- The relational model
- Ontologies
## Practice
- Data readiness levels
- Data wrangling in practice
- Exploratory data analysis
- Handling missing data (imputation, etc)

# Computer Science
- BNF
- Regular languages; context free grammars
- Parsers (and the Chomsky hierarchy)
- Lambda calculus
- Compilers
- Types
- Data structures
- Complexity

# Machine learning
## The two cultures
   - Theorise and estimate
   - Compute and test
## Approaches
- Bayesian methods
- Classical statistics
- Computer science
## Techniques
- Regression and Classification
- Hypothesis testing
- Deep learning
- Unsupervised modelling
- Generative models
- Feature engineering / Feature selection
- Overfitting and regularisation
- Model selection/comparison
- Model averaging
- Model evaluation (validation, test, accuracy metrics)
## When to use machine learning?
- What is even a good question for machine learning?

# Working with clients
- Scoping
- Collaborating with clients
- Common hurdles during scoping, development, adoption
- Handover

# Agile data science
- Baseline model
- Measure of success and evaluation platform
- Reproducible workflow for data science

# Systems, software, languages, libraries
- RDBMs and SQL
- NoSQL
- Python, R, Scala, Julia, Matlab, F#, etc: Pros and Cons, what are they good for
- Some common libraries: scikit-learn, Keras, Stan, tensorflow, NLTK, ...
- Distributed Computing (Hadoop, Spark)
- Parallel computing (for CPU, HPC, GPUs, FPGAs)
- Docker
- Kubernetes
- Using cloud platforms (e.g. Azure)


# Good old-fashioned AI
## Optimisation
- Mixed-integer linear programming
- Dynamic programming
- Gradient descent (use derivatives)
- Newton's method (use second order derivatives)
- Evolutionary programming, genetic algorithms (don't need a derivative)
- Bayesian Optimisation (don't need a derivative)

## Simulation
- Monte Carlo

# Visualisation
- Types of charts
- Interactive charts
- Guidance for effective visualisations
- Network graphs

# A compendium of terms
  - Entropy

# A compendium of problems
  - Record linkage
  - Clustering
  - Interpolation
  - Anomaly detection
  - Survival analysis
  - Classification
  - Prediction

# A compendium of named techniques

## Classification/Regression
- Linear and logistic regression
- k Nearest Neighbours (KNN)
- Support Vector Machine
- Gaussian processes
- Decision Trees
- Random Forrest
- Generalised linear models
- Naive Bayes
- Bayesian hierarchical models

## Clustering
- k-means
- Mixture of Gaussians
- Mixture models
- Topic modelling (Latent Dirichlet Allocation)

## Dimensionality reduction
- Factor analysis/Principal component Analysis
- Auto-encoder
- Word2Vec

## Regularisation
- LASSO regression (L1)
- Ridge regression (L2)
- penalised regression
- early stopping (implicit)
- drop out (in NNs)
- weight decay (in NNs)
- priors in Bayesian models

## Time-series data
- Kalman filter
- Time series autoregressive models (e.g. ARIMA)

## Deep Learning
- Multi Layer Perceptron
- Convolutional neural networks
- Recurrent neural networks
- LSTM
- Generative Adversarial Networks
- Variational Autoencoders
- Attention
- Transformers

## Inference
- Least squares method
- Maximum Likelihood Estimation
- Expectation maximisation
- Markov Chain Monte Carlo
- Particle Filter
- Sequential Monte Carlo
- Variational Inference

## Functions
- Softmax
- Sigmoid
- ReLu

## Function approximations
- Taylor series
- Fourier series

## Matrix decompositions
- LU
- Cholesky
- Eigendecomposition
- Singular Value decomposition

## Other
  - Fellegi-Sunter
  - Elastic nets
  - t-SNE
  - Self-Organizing Map (SOM), Self-Organizing Feature Map (SOFM)
  - Nonparametric Bayes
  - Regular expressions
  - Conditional Random Fields
  - Hidden Markov Models
  - Reinforcement Learning
  - Agent Based Modelling
  - Boosting and bagging
  - Web scraping
  - ANOVA
  - Transfer Learning
  - Federated Learning
  - MICE (Multivariate Imputation by Chained Equations)
