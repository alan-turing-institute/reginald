
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="..">
      
      
        <link rel="next" href="../ENVIRONMENT_VARIABLES/">
      
      
      <link rel="icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.0, mkdocs-material-9.5.26">
    
    
      
        <title>Models - Reginald: a simple Slack bot written in Python</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.6543a935.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../assets/_mkdocstrings.css">
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#reginald-models" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="Reginald: a simple Slack bot written in Python" class="md-header__button md-logo" aria-label="Reginald: a simple Slack bot written in Python" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Reginald: a simple Slack bot written in Python
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Models
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme)" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m14.3 16-.7-2h-3.2l-.7 2H7.8L11 7h2l3.2 9h-1.9M20 8.69V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69m-9.15 3.96h2.3L12 9l-1.15 3.65Z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_2" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to system preference"  type="radio" name="__palette" id="__palette_2">
    
      <label class="md-header__button md-icon" title="Switch to system preference" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12c0-2.42-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var media,input,key,value,palette=__md_get("__palette");if(palette&&palette.color){"(prefers-color-scheme)"===palette.color.media&&(media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']"),palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent"));for([key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/alan-turing-institute/reginald/" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="Reginald: a simple Slack bot written in Python" class="md-nav__button md-logo" aria-label="Reginald: a simple Slack bot written in Python" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    Reginald: a simple Slack bot written in Python
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/alan-turing-institute/reginald/" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    Models
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    Models
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#llama-index-models" class="md-nav__link">
    <span class="md-ellipsis">
      llama-index Models
    </span>
  </a>
  
    <nav class="md-nav" aria-label="llama-index Models">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#data-index-options" class="md-nav__link">
    <span class="md-ellipsis">
      Data index options
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#llama-index-models-with-self-hosted-llm" class="md-nav__link">
    <span class="md-ellipsis">
      llama-index models with self-hosted LLM
    </span>
  </a>
  
    <nav class="md-nav" aria-label="llama-index models with self-hosted LLM">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#llama-index-llama-cpp-model" class="md-nav__link">
    <span class="md-ellipsis">
      llama-index-llama-cpp Model
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama-index-hf-model" class="md-nav__link">
    <span class="md-ellipsis">
      llama-index-hf Model
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#llama-index-models-using-an-api" class="md-nav__link">
    <span class="md-ellipsis">
      llama-index models using an API
    </span>
  </a>
  
    <nav class="md-nav" aria-label="llama-index models using an API">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#llama-index-gpt-azure-model" class="md-nav__link">
    <span class="md-ellipsis">
      llama-index-gpt-azure Model
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama-index-gpt-openai-model" class="md-nav__link">
    <span class="md-ellipsis">
      llama-index-gpt-openai Model
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#chat-completion-models" class="md-nav__link">
    <span class="md-ellipsis">
      chat-completion Models
    </span>
  </a>
  
    <nav class="md-nav" aria-label="chat-completion Models">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#chat-completion-azure-model" class="md-nav__link">
    <span class="md-ellipsis">
      chat-completion-azure Model
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#chat-completion-openai-model" class="md-nav__link">
    <span class="md-ellipsis">
      chat-completion-openai Model
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../ENVIRONMENT_VARIABLES/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Configuration
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="https://github.com/alan-turing-institute/reginald/issues" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Issues
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" >
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Reference
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            Reference
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_1" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../reference/reginald/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    reginald
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_5_1" id="__nav_5_1_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_1">
            <span class="md-nav__icon md-icon"></span>
            reginald
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/reginald/cli/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    cli
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/reginald/defaults/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    defaults
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_1_3" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../reference/reginald/models/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    models
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_5_1_3" id="__nav_5_1_3_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_1_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_1_3">
            <span class="md-nav__icon md-icon"></span>
            models
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/reginald/models/app/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    app
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/reginald/models/base/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    base
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/reginald/models/chat_interact/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    chat_interact
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/reginald/models/create_index/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    create_index
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/reginald/models/download_from_fileshare/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    download_from_fileshare
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_1_3_6" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../reference/reginald/models/llama_index/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    llama_index
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_5_1_3_6" id="__nav_5_1_3_6_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="4" aria-labelledby="__nav_5_1_3_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_1_3_6">
            <span class="md-nav__icon md-icon"></span>
            llama_index
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/reginald/models/llama_index/base/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    base
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/reginald/models/llama_index/data_index_creator/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    data_index_creator
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/reginald/models/llama_index/llama_cpp_template/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama_cpp_template
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/reginald/models/llama_index/llama_index/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama_index
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/reginald/models/llama_index/llama_index_azure_openai/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama_index_azure_openai
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/reginald/models/llama_index/llama_index_hf/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama_index_hf
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/reginald/models/llama_index/llama_index_llama_cpp/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama_index_llama_cpp
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/reginald/models/llama_index/llama_index_ollama/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama_index_ollama
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/reginald/models/llama_index/llama_index_openai/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama_index_openai
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/reginald/models/llama_index/llama_utils/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama_utils
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/reginald/models/setup_llm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    setup_llm
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_1_3_8" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../reference/reginald/models/simple/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    simple
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_5_1_3_8" id="__nav_5_1_3_8_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="4" aria-labelledby="__nav_5_1_3_8_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_1_3_8">
            <span class="md-nav__icon md-icon"></span>
            simple
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/reginald/models/simple/chat_completion/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    chat_completion
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/reginald/models/simple/hello/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    hello
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/reginald/run/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    run
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/reginald/run_full_pipeline/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    run_full_pipeline
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_1_6" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../reference/reginald/slack_bot/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    slack_bot
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_5_1_6" id="__nav_5_1_6_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_1_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_1_6">
            <span class="md-nav__icon md-icon"></span>
            slack_bot
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/reginald/slack_bot/bot/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    bot
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/reginald/slack_bot/run_bot/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    run_bot
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/reginald/slack_bot/utils/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    utils
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/reginald/utils/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    utils
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#llama-index-models" class="md-nav__link">
    <span class="md-ellipsis">
      llama-index Models
    </span>
  </a>
  
    <nav class="md-nav" aria-label="llama-index Models">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#data-index-options" class="md-nav__link">
    <span class="md-ellipsis">
      Data index options
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#llama-index-models-with-self-hosted-llm" class="md-nav__link">
    <span class="md-ellipsis">
      llama-index models with self-hosted LLM
    </span>
  </a>
  
    <nav class="md-nav" aria-label="llama-index models with self-hosted LLM">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#llama-index-llama-cpp-model" class="md-nav__link">
    <span class="md-ellipsis">
      llama-index-llama-cpp Model
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama-index-hf-model" class="md-nav__link">
    <span class="md-ellipsis">
      llama-index-hf Model
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#llama-index-models-using-an-api" class="md-nav__link">
    <span class="md-ellipsis">
      llama-index models using an API
    </span>
  </a>
  
    <nav class="md-nav" aria-label="llama-index models using an API">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#llama-index-gpt-azure-model" class="md-nav__link">
    <span class="md-ellipsis">
      llama-index-gpt-azure Model
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llama-index-gpt-openai-model" class="md-nav__link">
    <span class="md-ellipsis">
      llama-index-gpt-openai Model
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#chat-completion-models" class="md-nav__link">
    <span class="md-ellipsis">
      chat-completion Models
    </span>
  </a>
  
    <nav class="md-nav" aria-label="chat-completion Models">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#chat-completion-azure-model" class="md-nav__link">
    <span class="md-ellipsis">
      chat-completion-azure Model
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#chat-completion-openai-model" class="md-nav__link">
    <span class="md-ellipsis">
      chat-completion-openai Model
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
  


<h1 id="reginald-models">Reginald Models</h1>
<p>We currently have the following models available:</p>
<ul>
<li><code>hello</code>: a simple model which responds to a message with a greeting and an emoji</li>
<li><code>llama-index-llama-cpp</code>: a model which uses the <a href="https://github.com/jerryjliu/llama_index"><code>llama-index</code></a> library to query a data index and then uses a quantised LLM (implemented using <a href="https://github.com/abetlen/llama-cpp-python"><code>llama-python-cpp</code></a>) to generate a response</li>
<li><code>llama-index-hf</code>: a model which uses the <a href="https://github.com/jerryjliu/llama_index"><code>llama-index</code></a> library to query a data index and then uses an LLM from <a href="https://huggingface.co/models">Huggingface</a> to generate a response</li>
<li><code>llama-index-gpt-azure</code>: a model which uses the <a href="https://github.com/jerryjliu/llama_index"><code>llama-index</code></a> library to query a data index and then uses the Azure OpenAI API to query a LLM to generate a response</li>
<li><code>llama-index-gpt-openai</code>: a model which uses the <a href="https://github.com/jerryjliu/llama_index"><code>llama-index</code></a> library to query a data index and then uses the OpenAI API to query a LLM to generate a response</li>
<li><code>chat-completion-azure</code>: a chat completion model which uses the Azure OpenAI API to query a LLM to generate a response (does not use <code>llama-index</code>)</li>
<li><code>chat-completion-openai</code>: a chat completion model which uses the OpenAI API to query a LLM to generate a response (does not use <code>llama-index</code>)</li>
</ul>
<h2 id="llama-index-models"><code>llama-index</code> Models</h2>
<p>The library has several models which use the <a href="https://github.com/jerryjliu/llama_index"><code>llama-index</code></a> library which allow us to easily augment an LLM with our own data. In particular, we use <code>llama-index</code> to ingest several data sources, including several public sources:</p>
<ul>
<li><a href="https://alan-turing-institute.github.io/REG-handbook/">The Research Engineering Group (REG) Handbook</a></li>
<li><a href="https://the-turing-way.netlify.app/">The Turing Way</a></li>
<li><a href="https://alan-turing-institute.github.io/rse-course/">The Research Software Engineering (RSE) course ran by REG</a></li>
<li><a href="https://alan-turing-institute.github.io/rds-course/">The Research Data Science (RDS) course ran by REG</a></li>
<li><a href="https://www.turing.ac.uk/">The public Turing website</a></li>
</ul>
<p>And also some private sources from our private GitHub repositories (using the repo&rsquo;s Wiki pages, issues and some selected files).</p>
<p>All of these (besides the public Turing website) are loaded using <a href="https://github.com/emptycrown/llama-hub"><code>llama-hub</code></a> <a href="https://llamahub.ai/l/github_repo">GitHub readers</a>. Hence, when we are first building up the data index, we must set up the GitHub access tokens (see the <a href="../">README</a> for more details), and you will only be able to build the <code>all_data</code> data index if you have access to our private repositories.</p>
<h3 id="data-index-options">Data index options</h3>
<p>When running the Reginald Slack bot, you can specify which data index to use using the <code>LLAMA_INDEX_WHICH_INDEX</code> environment variable (see the <a href="../ENVIRONMENT_VARIABLES/">environment variables README</a> for more details). The options are:
- <code>handbook</code>: only builds an index with the public REG handbook
- <code>wikis</code>: only builds an index with private REG repo Wiki pages
- <code>public</code>: builds an index with the all the public data listed above
- <code>all_data</code>: builds an index with all the data listed above including data from our private repo</p>
<p>Once a data index has been built, it will be saved in the <code>data</code> directory specified in the <code>reginald run_all</code> (or <code>reginald run_all_api_llm</code>) CLI arguments or the <code>LLAMA_INDEX_DATA_DIR</code> environment variable. If you want to force a new index to be built, you can use the <code>--force-new-index</code> or <code>-f</code> flag, or you can set the <code>LLAMA_INDEX_FORCE_NEW_INDEX</code> environment variable to <code>True</code>.</p>
<p>There are several options of the LLM to use with the <code>llama-index</code> models, some of which we have implemented in this library and which we discuss below.</p>
<h2 id="llama-index-models-with-self-hosted-llm"><code>llama-index</code> models with self-hosted LLM</h2>
<p>We have two models which involve hosting the LLM ourselves and using the <code>llama-index</code> library to query the data index and then generate a response using the LLM. These models are:</p>
<h3 id="llama-index-llama-cpp-model"><code>llama-index-llama-cpp</code> Model</h3>
<p>This model uses the <a href="https://github.com/abetlen/llama-cpp-python"><code>llama-cpp-python</code></a> library to host a quantised LLM. In our case, we have been using quantised versions of Meta&rsquo;s Llama-2 model uploaded by <a href="https://huggingface.co/TheBloke">TheBloke</a> on Huggingface&rsquo;s model hub. An example of running this model locally is:</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a>reginald<span class="w"> </span>run_all<span class="w"> </span><span class="se">\</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a><span class="w">  </span>--model<span class="w"> </span>llama-index-llama-cpp<span class="w"> </span><span class="se">\</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a><span class="w">  </span>--model-name<span class="w"> </span>https://huggingface.co/TheBloke/Llama-2-7b-Chat-GGUF/resolve/main/llama-2-7b-chat.Q4_K_M.gguf<span class="w"> </span><span class="se">\</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a><span class="w">  </span>--mode<span class="w"> </span>chat<span class="w"> </span><span class="se">\</span>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a><span class="w">  </span>--data-dir<span class="w"> </span>data/<span class="w"> </span><span class="se">\</span>
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a><span class="w">  </span>--which-index<span class="w"> </span>handbook<span class="w"> </span><span class="se">\</span>
</span><span id="__span-0-7"><a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a><span class="w">  </span>--max-input-size<span class="w"> </span><span class="m">4096</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-0-8"><a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a><span class="w">  </span>--n-gpu-layers<span class="w"> </span><span class="m">2</span>
</span></code></pre></div>
<p>Note that the <code>--n-gpu-layers</code> argument is optional and specifies the number of layers to offload to the GPU. If not specified, it will default to 0. See the <a href="https://github.com/abetlen/llama-cpp-python"><code>llama-cpp-python</code> README</a> to see how you can install the library with hardware acceleration.</p>
<p>Running this in a root of this repository will automatically pick up the data indices for the handbook in <code>data/llama_index_indices/handbook</code> directory.</p>
<p>Running this command requires about 7GB of RAM. We were able to run this on our M1 Pro (32GB) macbook pros with no issues and were able to run the <a href="https://huggingface.co/TheBloke/Llama-2-13B-chat-GGUF">Llama-2-13B-chat</a> model too.</p>
<p>If you wish to download the quantised model (as a <code>.gguf</code> file) and host it yourself, you can do so by passing the file name to the <code>--model-name</code> argument and using the <code>--is-path</code> flag (alternatively, you can re-run the above but first set the environment variable <code>LLAMA_INDEX_IS_PATH</code> to <code>True</code>):</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-1-1"><a id="__codelineno-1-1" name="__codelineno-1-1" href="#__codelineno-1-1"></a>reginald<span class="w"> </span>run_all<span class="w"> </span><span class="se">\</span>
</span><span id="__span-1-2"><a id="__codelineno-1-2" name="__codelineno-1-2" href="#__codelineno-1-2"></a><span class="w">  </span>--model<span class="w"> </span>llama-index-llama-cpp<span class="w"> </span><span class="se">\</span>
</span><span id="__span-1-3"><a id="__codelineno-1-3" name="__codelineno-1-3" href="#__codelineno-1-3"></a><span class="w">  </span>--model-name<span class="w"> </span>gguf_models/llama-2-7b-chat.Q4_K_M.gguf<span class="w"> </span><span class="se">\</span>
</span><span id="__span-1-4"><a id="__codelineno-1-4" name="__codelineno-1-4" href="#__codelineno-1-4"></a><span class="w">  </span>--is-path<span class="w"> </span><span class="se">\</span>
</span><span id="__span-1-5"><a id="__codelineno-1-5" name="__codelineno-1-5" href="#__codelineno-1-5"></a><span class="w">  </span>--mode<span class="w"> </span>chat<span class="w"> </span><span class="se">\</span>
</span><span id="__span-1-6"><a id="__codelineno-1-6" name="__codelineno-1-6" href="#__codelineno-1-6"></a><span class="w">  </span>--data-dir<span class="w"> </span>data/<span class="w"> </span><span class="se">\</span>
</span><span id="__span-1-7"><a id="__codelineno-1-7" name="__codelineno-1-7" href="#__codelineno-1-7"></a><span class="w">  </span>--which-index<span class="w"> </span>handbook<span class="w"> </span><span class="se">\</span>
</span><span id="__span-1-8"><a id="__codelineno-1-8" name="__codelineno-1-8" href="#__codelineno-1-8"></a><span class="w">  </span>--max-input-size<span class="w"> </span><span class="m">4096</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-1-9"><a id="__codelineno-1-9" name="__codelineno-1-9" href="#__codelineno-1-9"></a><span class="w">  </span>--n-gpu-layers<span class="w"> </span><span class="m">2</span>
</span></code></pre></div>
<p>given that the <code>llama-2-7b-chat.Q4_K_M.gguf</code> file is in a <code>gguf_models</code> directory.</p>
<h3 id="llama-index-hf-model"><code>llama-index-hf</code> Model</h3>
<p>This model uses an LLM from <a href="https://huggingface.co/models">Huggingface</a> to generate a response. An example of running this model locally is:</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-2-1"><a id="__codelineno-2-1" name="__codelineno-2-1" href="#__codelineno-2-1"></a>reginald<span class="w"> </span>run_all<span class="w"> </span><span class="se">\</span>
</span><span id="__span-2-2"><a id="__codelineno-2-2" name="__codelineno-2-2" href="#__codelineno-2-2"></a><span class="w">  </span>--model<span class="w"> </span>llama-index-hf<span class="w"> </span><span class="se">\</span>
</span><span id="__span-2-3"><a id="__codelineno-2-3" name="__codelineno-2-3" href="#__codelineno-2-3"></a><span class="w">  </span>--model-name<span class="w"> </span>microsoft/phi-1_5<span class="w"> </span><span class="se">\</span>
</span><span id="__span-2-4"><a id="__codelineno-2-4" name="__codelineno-2-4" href="#__codelineno-2-4"></a><span class="w">  </span>--mode<span class="w"> </span>chat<span class="w"> </span><span class="se">\</span>
</span><span id="__span-2-5"><a id="__codelineno-2-5" name="__codelineno-2-5" href="#__codelineno-2-5"></a><span class="w">  </span>--data-dir<span class="w"> </span>data/<span class="w"> </span><span class="se">\</span>
</span><span id="__span-2-6"><a id="__codelineno-2-6" name="__codelineno-2-6" href="#__codelineno-2-6"></a><span class="w">  </span>--which-index<span class="w"> </span>handbook<span class="w"> </span><span class="se">\</span>
</span><span id="__span-2-7"><a id="__codelineno-2-7" name="__codelineno-2-7" href="#__codelineno-2-7"></a><span class="w">  </span>--max-input-size<span class="w"> </span><span class="m">2048</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-2-8"><a id="__codelineno-2-8" name="__codelineno-2-8" href="#__codelineno-2-8"></a><span class="w">  </span>--device<span class="w"> </span>auto
</span></code></pre></div>
<p>Note currently the <a href="https://huggingface.co/microsoft/phi-1_5"><code>microsoft/phi-1_5</code></a> model has a predefined maximum length of 2048 context length. Hence, we must set the <code>--max-input-size</code> argument to be less than or equal to 2048 as the default value for this argument is 4096 as we tend to use the <code>llama-cpp-python</code> model more. We also set the <code>--device</code> argument to be <code>auto</code> so that the model will be run on any hardware acceleration if available.</p>
<h2 id="llama-index-models-using-an-api"><code>llama-index</code> models using an API</h2>
<p>We have two models which use an API to query a LLM to generate a response. These models are:</p>
<h3 id="llama-index-gpt-azure-model"><code>llama-index-gpt-azure</code> Model</h3>
<p>To use this model, you must set the following environment variables:
- <code>OPENAI_AZURE_API_BASE</code>: API base for Azure OpenAI
- <code>OPENAI_AZURE_API_KEY</code>: API key for Azure OpenAI</p>
<p>An example of running this model locally is:</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-3-1"><a id="__codelineno-3-1" name="__codelineno-3-1" href="#__codelineno-3-1"></a>reginald<span class="w"> </span>run_all<span class="w"> </span><span class="se">\</span>
</span><span id="__span-3-2"><a id="__codelineno-3-2" name="__codelineno-3-2" href="#__codelineno-3-2"></a><span class="w">  </span>--model<span class="w"> </span>llama-index-gpt-azure<span class="w"> </span><span class="se">\</span>
</span><span id="__span-3-3"><a id="__codelineno-3-3" name="__codelineno-3-3" href="#__codelineno-3-3"></a><span class="w">  </span>--model-name<span class="w"> </span><span class="s2">&quot;reginald-gpt35-turbo&quot;</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-3-4"><a id="__codelineno-3-4" name="__codelineno-3-4" href="#__codelineno-3-4"></a><span class="w">  </span>--mode<span class="w"> </span>chat<span class="w"> </span><span class="se">\</span>
</span><span id="__span-3-5"><a id="__codelineno-3-5" name="__codelineno-3-5" href="#__codelineno-3-5"></a><span class="w">  </span>--data-dir<span class="w"> </span>data/<span class="w"> </span><span class="se">\</span>
</span><span id="__span-3-6"><a id="__codelineno-3-6" name="__codelineno-3-6" href="#__codelineno-3-6"></a><span class="w">  </span>--which-index<span class="w"> </span>handbook
</span></code></pre></div>
<p>Note that <code>"reginald-gpt35-turbo"</code> is the name of our deployment of the &ldquo;gpt-3.5-turbo&rdquo; model on Azure. This probably is different on your deployment and resource group on Azure.</p>
<h3 id="llama-index-gpt-openai-model"><code>llama-index-gpt-openai</code> Model</h3>
<p>To use this model, you must set the <code>OPENAI_API_KEY</code> environment variable and set this to be an API key for OpenAI.</p>
<p>An example of running this model locally is:</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-4-1"><a id="__codelineno-4-1" name="__codelineno-4-1" href="#__codelineno-4-1"></a>reginald<span class="w"> </span>run_all<span class="w"> </span><span class="se">\</span>
</span><span id="__span-4-2"><a id="__codelineno-4-2" name="__codelineno-4-2" href="#__codelineno-4-2"></a><span class="w">  </span>--model<span class="w"> </span>llama-index-gpt-openai<span class="w"> </span><span class="se">\</span>
</span><span id="__span-4-3"><a id="__codelineno-4-3" name="__codelineno-4-3" href="#__codelineno-4-3"></a><span class="w">  </span>--model-name<span class="w"> </span><span class="s2">&quot;gpt-3.5-turbo&quot;</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-4-4"><a id="__codelineno-4-4" name="__codelineno-4-4" href="#__codelineno-4-4"></a><span class="w">  </span>--mode<span class="w"> </span>chat<span class="w"> </span><span class="se">\</span>
</span><span id="__span-4-5"><a id="__codelineno-4-5" name="__codelineno-4-5" href="#__codelineno-4-5"></a><span class="w">  </span>--data-dir<span class="w"> </span>data/<span class="w"> </span><span class="se">\</span>
</span><span id="__span-4-6"><a id="__codelineno-4-6" name="__codelineno-4-6" href="#__codelineno-4-6"></a><span class="w">  </span>--which-index<span class="w"> </span>handbook
</span></code></pre></div>
<h2 id="chat-completion-models"><code>chat-completion</code> Models</h2>
<p>The library also has several models which use the OpenAI API (or the Azure OpenAI API) to query a LLM to generate a response. These models do not use the <code>llama-index</code> library and hence do not use a data index - these are purely chat completion models.</p>
<h3 id="chat-completion-azure-model"><code>chat-completion-azure</code> Model</h3>
<p>To use this model, you must set the following environment variables:
- <code>OPENAI_AZURE_API_BASE</code>: API base for Azure OpenAI
- <code>OPENAI_AZURE_API_KEY</code>: API key for Azure OpenAI</p>
<p>An example of running this model locally is:</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-5-1"><a id="__codelineno-5-1" name="__codelineno-5-1" href="#__codelineno-5-1"></a>reginald<span class="w"> </span>run_all<span class="w"> </span><span class="se">\</span>
</span><span id="__span-5-2"><a id="__codelineno-5-2" name="__codelineno-5-2" href="#__codelineno-5-2"></a><span class="w">  </span>--model<span class="w"> </span>chat-completion-azure<span class="w"> </span><span class="se">\</span>
</span><span id="__span-5-3"><a id="__codelineno-5-3" name="__codelineno-5-3" href="#__codelineno-5-3"></a><span class="w">  </span>--model-name<span class="w"> </span><span class="s2">&quot;reginald-curie&quot;</span>
</span></code></pre></div>
<p>Note that <code>"reginald-curie"</code> is the name of our deployment of a fine-tuned model on Azure. This probably is different on your deployment and resource group on Azure.
With Azure&rsquo;s AI Studio, it is possible to fine-tune your own model with Q&amp;A pairs (see <a href="https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/fine-tuning">here</a> for more details).</p>
<h3 id="chat-completion-openai-model"><code>chat-completion-openai</code> Model</h3>
<p>To use this model, you must set the <code>OPENAI_API_KEY</code> environment variable and set this to be an API key for OpenAI.</p>
<p>An example of running this model locally is:</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-6-1"><a id="__codelineno-6-1" name="__codelineno-6-1" href="#__codelineno-6-1"></a>reginald<span class="w"> </span>run_all<span class="w"> </span><span class="se">\</span>
</span><span id="__span-6-2"><a id="__codelineno-6-2" name="__codelineno-6-2" href="#__codelineno-6-2"></a><span class="w">  </span>--model<span class="w"> </span>chat-completion-openai<span class="w"> </span><span class="se">\</span>
</span><span id="__span-6-3"><a id="__codelineno-6-3" name="__codelineno-6-3" href="#__codelineno-6-3"></a><span class="w">  </span>--model-name<span class="w"> </span><span class="s2">&quot;gpt-3.5-turbo&quot;</span>
</span></code></pre></div>












                
              </article>
            </div>
          
          
  <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var tab,labels=set.querySelector(".tabbed-labels");for(tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>

<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "..", "features": ["content.code.copy", "content.tabs.link"], "search": "../assets/javascripts/workers/search.b8dbb3d2.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../assets/javascripts/bundle.ad660dcc.min.js"></script>
      
    
  </body>
</html>